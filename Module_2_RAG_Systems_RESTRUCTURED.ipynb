{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Module 2: RAG Systems - Production Implementation\n\n## \ud83c\udfaf What You'll Learn\n\nBuild production-ready Retrieval-Augmented Generation (RAG) systems with security.\n\n**Time to Complete:** 3-4 hours\n\n---\n\n## \ud83d\udcda Module Outline\n\n### Part 1: Understanding RAG (30 min)\n- What is RAG and why use it\n- The three stages: Ingest \u2192 Retrieve \u2192 Generate\n- When RAG helps vs. hurts\n\n### Part 2: Chunking Strategies (45 min)\n- Why chunking matters\n- 3 strategies: Fixed, Sentence, Semantic\n- Choosing the right strategy\n\n### Part 3: Retrieval Methods (60 min)\n- Vector search basics\n- BM25 (keyword search)\n- Hybrid search (combining both)\n- Reranking for precision\n\n### Part 4: Security & RBAC (45 min)\n- Role-based access control\n- Audit logging\n- Multi-tenant isolation\n\n### Part 5: Practice & Review (30 min)\n- Build your own RAG\n- Practice exercises\n\n---\n\n## \ud83e\udded Learning Path\n\n```\n[Start] \u2192 Understand RAG \u2192 Learn Chunking \u2192 Master Retrieval\n   \u2193\nAdd Security \u2192 Practice \u2192 [Complete]\n```\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Setup\n\n**Time:** 5 minutes"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "%pip install -q chromadb sentence-transformers rank-bm25\n%pip install -q pandas numpy matplotlib\n\nimport re\nimport hashlib\nimport numpy as np\nfrom typing import List, Dict, Any\nfrom dataclasses import dataclass\nfrom collections import defaultdict\nfrom datetime import datetime\n\nprint('\u2705 Dependencies loaded!')\nprint('\ud83d\udcd6 Ready to learn RAG systems!')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n# Part 1: Understanding RAG\n\n**Time:** 30 min | **Difficulty:** Beginner\n\n## \ud83c\udfaf The Problem RAG Solves\n\n**Without RAG:**\n- LLM only knows what it learned during training\n- Can't access your private documents\n- Makes up answers (hallucinates)\n- Knowledge cutoff date\n\n**With RAG:**\n- Retrieves relevant documents\n- Grounds answers in YOUR data\n- Reduces hallucinations\n- Always up-to-date\n\n## \ud83d\udd04 How RAG Works (3 Stages)\n\n### Stage 1: Ingest (One-time setup)\n```\nYour Documents \u2192 Split into Chunks \u2192 Convert to Embeddings \u2192 Store in Vector DB\n```\n\n### Stage 2: Retrieve (Per query)\n```\nUser Question \u2192 Convert to Embedding \u2192 Find Similar Chunks \u2192 Return Top-K\n```\n\n### Stage 3: Generate (Per query)\n```\nQuestion + Retrieved Chunks \u2192 Send to LLM \u2192 Get Grounded Answer\n```\n\n## \u2696\ufe0f When to Use RAG\n\n**Use RAG when:**\n- \u2705 You have private/proprietary documents\n- \u2705 Knowledge changes frequently\n- \u2705 Need citations/sources\n- \u2705 Need access control (different users see different docs)\n\n**Don't use RAG when:**\n- \u274c Questions are about general knowledge (LLM already knows)\n- \u274c Documents are too small (just put in prompt)\n- \u274c Need real-time data (use API tools instead)\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n# Part 2: Chunking Strategies\n\n**Time:** 45 min | **Difficulty:** Intermediate\n\n## \ud83c\udfaf Why Chunking Matters\n\n**Problem:** Documents are too long for LLM context window.\n\n**Solution:** Split into smaller chunks that fit in context.\n\n**Challenge:** How you split affects retrieval quality!\n\n## \ud83d\udccf Three Main Strategies\n\n### 1. Fixed-Size Chunking\n**What:** Split every N characters\n**Pros:** Simple, fast\n**Cons:** Breaks sentences mid-way\n**Use when:** Code, highly structured data\n\n### 2. Sentence-Aware Chunking\n**What:** Split at sentence boundaries\n**Pros:** Preserves meaning, readable\n**Cons:** Slightly complex\n**Use when:** Articles, policies, Q&A documents\n\n### 3. Semantic Chunking\n**What:** Split when topic changes\n**Pros:** Best retrieval quality\n**Cons:** Slowest, most complex\n**Use when:** Long-form content, books\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcbb Code Example: Document Chunker\n\n**What this does:**\n- Implements sentence-aware chunking\n- Adds overlap between chunks (important!)\n- Tracks metadata\n\n**Why overlap matters:** Last sentence of Chunk 1 = First sentence of Chunk 2\n\u2192 Prevents information loss at boundaries"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "@dataclass\nclass Chunk:\n    text: str\n    chunk_id: str\n    start_idx: int\n    end_idx: int\n\nclass DocumentChunker:\n    \"\"\"Split documents into retrievable chunks.\"\"\"\n    \n    def __init__(self, chunk_size=400, overlap=50):\n        self.chunk_size = chunk_size  # Target size in characters\n        self.overlap = overlap  # Overlap to prevent information loss\n    \n    def chunk_by_sentences(self, text: str, doc_id: str) -> List[Chunk]:\n        \"\"\"Chunk by sentence boundaries (recommended for most docs).\"\"\"\n        \n        # Split into sentences\n        sentences = re.split(r'(?<=[.!?])\\s+', text)\n        \n        chunks = []\n        current_chunk_sentences = []\n        current_length = 0\n        \n        for sentence in sentences:\n            sentence_len = len(sentence)\n            \n            # If adding this sentence exceeds limit, create chunk\n            if current_length + sentence_len > self.chunk_size and current_chunk_sentences:\n                # Create chunk\n                chunk_text = ' '.join(current_chunk_sentences)\n                chunks.append(Chunk(\n                    text=chunk_text,\n                    chunk_id=f'{doc_id}_chunk_{len(chunks)}',\n                    start_idx=0,\n                    end_idx=len(chunk_text)\n                ))\n                \n                # Overlap: Keep last sentence for next chunk\n                if len(current_chunk_sentences) > 1:\n                    current_chunk_sentences = current_chunk_sentences[-1:]\n                    current_length = len(current_chunk_sentences[0])\n                else:\n                    current_chunk_sentences = []\n                    current_length = 0\n            \n            current_chunk_sentences.append(sentence)\n            current_length += sentence_len\n        \n        # Don't forget the last chunk!\n        if current_chunk_sentences:\n            chunk_text = ' '.join(current_chunk_sentences)\n            chunks.append(Chunk(\n                text=chunk_text,\n                chunk_id=f'{doc_id}_chunk_{len(chunks)}',\n                start_idx=0,\n                end_idx=len(chunk_text)\n            ))\n        \n        return chunks\n\n# \ud83d\udcdd Try it!\nsample_doc = \"\"\"Company Leave Policy\n\nFull-time employees with 1-3 years tenure get 15 days annual leave.\nPart-time employees get pro-rated leave.\nMedical leave requires a doctor's note after 3 consecutive days.\n\"\"\"\n\nchunker = DocumentChunker(chunk_size=100, overlap=20)  # Small for demo\nchunks = chunker.chunk_by_sentences(sample_doc, 'policy_doc')\n\nprint(f\"\ud83d\udcc4 Original: {len(sample_doc)} characters\")\nprint(f\"\u2702\ufe0f  Chunked into: {len(chunks)} chunks\\n\")\n\nfor i, chunk in enumerate(chunks, 1):\n    print(f\"Chunk {i}: {len(chunk.text)} chars\")\n    print(f\"  {chunk.text[:80]}...\\n\")\n\nprint(\"\ud83d\udca1 Notice: Chunks have some overlap to preserve context!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \u2705 Section Summary: Chunking\n\n### What You Learned:\n1. \u2713 Documents must be split to fit context limits\n2. \u2713 Sentence-aware chunking preserves meaning\n3. \u2713 Overlap prevents information loss at boundaries\n4. \u2713 Chunk size affects retrieval quality\n\n### Key Takeaways:\n- \ud83d\udccc **Recommended size: 400-600 characters** (or 100-150 tokens)\n- \ud83d\udccc **Always use overlap** (50-100 characters)\n- \ud83d\udccc **Sentence-aware > fixed-size** for most documents\n- \ud83d\udccc **Test different sizes** - optimal varies by content\n\n### Common Mistakes:\n- \u274c Chunks too large (reduces retrieval precision)\n- \u274c Chunks too small (loses context)\n- \u274c No overlap (information loss at boundaries)\n- \u274c Breaking mid-sentence (confuses retrieval)\n\n### Quick Guide:\n- **Articles/Policies**: 400 chars, sentence-aware\n- **Code**: 512 tokens, fixed-size\n- **Books**: 800 chars, semantic (topic-based)\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n# Part 3: Retrieval Methods\n\n**Time:** 60 min | **Difficulty:** Intermediate\n\n## \ud83c\udfaf Goal: Find the Most Relevant Chunks\n\n## \ud83d\udd0d Three Approaches\n\n### 1. Vector Search (Semantic)\n**How it works:**\n- Convert text to embeddings (vectors)\n- Find chunks with similar vectors\n- Uses cosine similarity\n\n**Good for:** Understanding meaning, paraphrases\n**Example:** Query \"PTO\" finds \"vacation days\"\n\n### 2. BM25 (Keyword)\n**How it works:**\n- Statistical keyword matching\n- Like traditional search engines\n\n**Good for:** Exact terms, IDs, names\n**Example:** Query \"Section 3.2\" finds exact section\n\n### 3. Hybrid (Best!)\n**How it works:**\n- Combine vector + BM25 scores\n- Get best of both worlds\n\n**Good for:** Production systems\n**Improvement:** +20-30% over single method\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcbb Code Example: Hybrid Search\n\n**What this shows:**\n- How to combine BM25 and vector search\n- Weighted fusion of scores\n- Comparison of methods\n\n**Study tip:** Run with the sample data, then try your own documents."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Simple hybrid retrieval demo\nfrom rank_bm25 import BM25Okapi\n\nclass SimpleHybridRetriever:\n    \"\"\"Combine keyword and semantic search.\"\"\"\n    \n    def __init__(self):\n        self.documents = []\n        self.bm25 = None\n    \n    def index(self, documents: List[str]):\n        \"\"\"Index documents.\"\"\"\n        self.documents = documents\n        \n        # Build BM25 index (keyword search)\n        tokenized = [doc.lower().split() for doc in documents]\n        self.bm25 = BM25Okapi(tokenized)\n        \n        print(f\"\u2705 Indexed {len(documents)} documents\")\n    \n    def search_bm25(self, query: str, top_k=3) -> List[Tuple[int, float]]:\n        \"\"\"Keyword search.\"\"\"\n        tokens = query.lower().split()\n        scores = self.bm25.get_scores(tokens)\n        \n        # Get top-k\n        top_indices = np.argsort(scores)[::-1][:top_k]\n        return [(idx, scores[idx]) for idx in top_indices]\n    \n    def search_hybrid(self, query: str, top_k=3) -> List[Tuple[int, float]]:\n        \"\"\"Hybrid search (for demo, just using BM25).\"\"\"\n        # In production: combine with vector search\n        return self.search_bm25(query, top_k)\n\n# \ud83d\udcdd Try it!\ntest_docs = [\n    'Python is a programming language used for data science and machine learning.',\n    'Machine learning models require large datasets for training.',\n    'Natural language processing helps computers understand human language.',\n    'Vector databases store embeddings for similarity search.',\n    'RAG combines retrieval with generation for better accuracy.',\n]\n\nprint(\"\ud83d\udd0d HYBRID SEARCH DEMONSTRATION\\n\")\n\nretriever = SimpleHybridRetriever()\nretriever.index(test_docs)\n\n# Test queries\nqueries = [\n    'Python machine learning',\n    'NLP language understanding',\n    'vector similarity',\n]\n\nfor query in queries:\n    print(f\"\\nQuery: '{query}'\")\n    print(\"-\" * 70)\n    \n    results = retriever.search_hybrid(query, top_k=2)\n    \n    for rank, (idx, score) in enumerate(results, 1):\n        print(f\"{rank}. [Score: {score:.2f}] {test_docs[idx][:60]}...\")\n\nprint(\"\\n\\n\ud83d\udca1 Tip: Hybrid search combines semantic understanding + keyword matching!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \u2705 Section Summary: Retrieval\n\n### What You Learned:\n1. \u2713 Vector search finds semantic matches\n2. \u2713 BM25 finds keyword matches\n3. \u2713 Hybrid combines both for best results\n4. \u2713 Top-k parameter controls how many chunks to retrieve\n\n### Key Takeaways:\n- \ud83d\udccc **Vector search**: Good for paraphrases (\"PTO\" \u2192 \"vacation\")\n- \ud83d\udccc **BM25**: Good for exact terms (\"Section 3.2\")\n- \ud83d\udccc **Hybrid**: Best for production (+20-30% accuracy)\n- \ud83d\udccc **Reranking**: Add cross-encoder for even better results\n\n### Common Mistakes:\n- \u274c Using only vector search (misses exact term matches)\n- \u274c Using only keyword search (misses semantic matches)\n- \u274c top_k too high (retrieves irrelevant chunks)\n- \u274c top_k too low (misses relevant information)\n\n### Optimal Settings:\n- **top_k**: Start with 5, tune based on evaluation\n- **Hybrid weight (alpha)**: 0.5 (equal weight BM25 and vector)\n- **Similarity threshold**: 0.7 (filter low-confidence matches)\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n# Part 4: Security - RBAC and Audit Logging\n\n**Time:** 45 min | **Difficulty:** Advanced\n\n## \ud83c\udfaf The Security Challenge\n\n**Problem:** Different users should see different documents.\n\n**Example:**\n- Public users: Only public docs\n- Employees: Public + internal docs\n- HR: All docs including compensation\n\n## \ud83d\udd10 Solution: Role-Based Access Control (RBAC)\n\n**Key concept:**\n1. Tag each document with allowed roles\n2. Filter retrieval results by user's role\n3. Log all accesses for audit\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcbb Code Example: Secure RAG with RBAC\n\n**What this shows:**\n- Documents tagged with allowed roles\n- Retrieval filtered by user role\n- Audit log for compliance\n\n**Study progression:**\n1. See how documents are ingested (line 20)\n2. Understand retrieval filtering (line 35)\n3. Notice audit logging (line 50)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "class SecureRAG:\n    \"\"\"RAG with role-based access control.\"\"\"\n    \n    def __init__(self):\n        self.documents = []  # In production: vector DB\n        self.audit_log = []\n    \n    def ingest(self, text: str, doc_id: str, allowed_roles: set):\n        \"\"\"Add document with access control.\"\"\"\n        self.documents.append({\n            'doc_id': doc_id,\n            'text': text,\n            'allowed_roles': allowed_roles\n        })\n        print(f\"\u2705 Ingested: {doc_id} (allowed: {allowed_roles})\")\n    \n    def retrieve(self, query: str, user_role: str, top_k=2) -> List[dict]:\n        \"\"\"Retrieve documents user can access.\"\"\"\n        \n        # Filter by role\n        accessible = [\n            doc for doc in self.documents\n            if user_role in doc['allowed_roles'] or 'public' in doc['allowed_roles']\n        ]\n        \n        # Log access\n        self._log_access(query, user_role, len(accessible))\n        \n        # In production: do actual similarity search\n        # For demo: return all accessible (limited to top_k)\n        return accessible[:top_k]\n    \n    def _log_access(self, query: str, role: str, results: int):\n        \"\"\"Audit logging for compliance.\"\"\"\n        self.audit_log.append({\n            'timestamp': datetime.utcnow().isoformat(),\n            'query': query[:50],\n            'user_role': role,\n            'results_count': results\n        })\n\n# \ud83e\uddea Test RBAC\nprint(\"\ud83d\udd12 SECURE RAG DEMONSTRATION\\n\")\n\nrag = SecureRAG()\n\n# Ingest with different access levels\nrag.ingest('Company holidays: Jan 1, Jul 4, Dec 25', 'holidays', {'public', 'employee', 'hr'})\nrag.ingest('Leave policy: 15 days after 1 year', 'leave', {'employee', 'hr'})\nrag.ingest('L4 Engineer salary: $150K-$180K', 'compensation', {'hr'})  # HR only!\n\nprint(\"\\n\ud83d\udd0d Testing access control:\\n\")\n\n# Test different roles\nfor query, role in [('holidays', 'public'), ('salary', 'employee'), ('salary', 'hr')]:\n    results = rag.retrieve(query, role, top_k=5)\n    print(f\"Query: '{query}' | Role: {role:<10} | Results: {len(results)}\")\n    for r in results:\n        print(f\"  \u2192 {r['doc_id']}\")\n    print()\n\nprint(\"\ud83d\udca1 Notice: 'employee' can't see salary, but 'hr' can!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \u2705 Section Summary: Security\n\n### What You Learned:\n1. \u2713 Different users need different document access\n2. \u2713 RBAC filters results by user role\n3. \u2713 Audit logs track all accesses\n4. \u2713 Security prevents data leakage\n\n### Key Takeaways:\n- \ud83d\udccc **Tag at ingestion** - mark allowed roles when indexing\n- \ud83d\udccc **Filter at retrieval** - only return allowed documents\n- \ud83d\udccc **Log everything** - audit trail for compliance\n- \ud83d\udccc **Default to most restrictive** - require explicit permission\n\n### Common Mistakes:\n- \u274c Filtering in application (too late, already retrieved)\n- \u274c No audit logging (can't prove compliance)\n- \u274c Using user input for role (security bypass!)\n- \u274c Not testing cross-tenant access\n\n### Security Checklist:\n- [ ] Documents tagged with allowed roles\n- [ ] Retrieval filters by role\n- [ ] Audit log retention (1+ years)\n- [ ] Regular access reviews\n- [ ] Test unauthorized access attempts\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n# \ud83d\udcdd Module 2 Review & Practice\n\n## \ud83c\udf93 Concepts Mastered\n\n### RAG Fundamentals\n- \u2705 Why RAG improves accuracy\n- \u2705 Three stages: Ingest \u2192 Retrieve \u2192 Generate\n- \u2705 When to use RAG\n\n### Chunking\n- \u2705 Why chunking matters\n- \u2705 Sentence-aware strategy\n- \u2705 Importance of overlap\n\n### Retrieval\n- \u2705 Vector vs. keyword search\n- \u2705 Hybrid search benefits\n- \u2705 Top-k selection\n\n### Security\n- \u2705 RBAC implementation\n- \u2705 Audit logging\n- \u2705 Multi-tenant isolation\n\n---\n\n## \ud83c\udfaf Practice Exercises\n\n### Exercise 1: Chunking Strategy (Medium)\nYou have a 50-page PDF policy document. Which chunking strategy and why?\n\n<details>\n<summary>Show answer</summary>\n\n**Recommendation:** Sentence-aware with 400-char chunks, 50-char overlap\n\n**Why:**\n- Policy documents have clear sentences\n- Need to preserve complete rules (sentence-aware helps)\n- 400 chars \u2248 1-2 paragraphs (good granularity)\n- Overlap prevents losing info at boundaries\n\n**Alternative:** Semantic chunking if document has clear sections\n</details>\n\n### Exercise 2: Precision vs Recall (Hard)\nYour RAG has:\n- Precision: 40% (many irrelevant chunks retrieved)\n- Recall: 90% (finds almost all relevant chunks)\n\nUsers complain about irrelevant results. What do you do?\n\n<details>\n<summary>Show answer</summary>\n\n**Root cause:** top_k too high + no reranking\n\n**Solutions (in order of impact):**\n1. **Add reranking** (+30% precision)\n   - Use cross-encoder to rerank top results\n   - Most impactful single improvement\n\n2. **Reduce top_k** (+15% precision)\n   - If using top_k=10, try top_k=5\n   - Fewer results = higher precision\n\n3. **Add similarity threshold** (+20% precision)\n   - Only return chunks above 0.7 similarity\n   - Filters low-confidence matches\n\n4. **Better chunking** (+10% both metrics)\n   - Semantic chunking preserves context better\n\n**Expected:** 40% \u2192 80%+ precision\n</details>\n\n---\n\n## \ud83c\udf93 Module 2 Complete!\n\n**Time invested:** 3-4 hours\n\n### \ud83d\udcda Next Module:\n**Module 3: LangChain** - Learn to build chains, agents, and evaluation frameworks\n\n---"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}