{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Module 3: LangChain - Chains, Agents, Evaluation\n\n## \ud83c\udfaf Learning Goals\n\nMaster LangChain for production systems: chains, agents, and systematic evaluation.\n\n**Time:** 4-5 hours | **Difficulty:** Intermediate-Advanced\n\n---\n\n## \ud83d\udcda What You'll Build\n\nBy the end of this module:\n1. Robust chains with auto-retry\n2. ReAct agents that use tools\n3. Memory management systems\n4. Complete evaluation framework\n\n---\n\n## \ud83d\uddfa\ufe0f Module Structure\n\n### Part 1: Understanding Chains (30 min)\n- What are chains\n- When to use them\n- Chain vs Agent\n\n### Part 2: Building Robust Chains (60 min)\n- Error handling\n- Retry logic\n- Validation\n\n### Part 3: Agents (60 min)\n- ReAct pattern\n- Tool integration\n- Multi-step reasoning\n\n### Part 4: Memory (45 min)\n- Managing conversation context\n- Token budgets\n- Memory strategies\n\n### Part 5: Evaluation (60 min)\n- Why evaluation matters\n- Building test suites\n- Regression detection\n\n### Part 6: Practice (30 min)\n- Exercises and review\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Setup\n\n**Time:** 5 minutes"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "%pip install -q langchain langchain-community langchain-openai\n%pip install -q pydantic pandas numpy\n\nimport json\nimport time\nimport pandas as pd\nimport numpy as np\nfrom typing import Callable, Any, List, Dict\nfrom pydantic import BaseModel, Field\nfrom collections import defaultdict\n\nprint('\u2705 LangChain environment ready!')\nprint('\ud83d\udcd6 Ready to build chains and agents!')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n# Part 1: Understanding Chains\n\n**Time:** 30 min | **Difficulty:** Beginner\n\n## \ud83c\udfaf What is a Chain?\n\n**Simple definition:** A chain connects multiple steps into a pipeline.\n\n**Example pipeline:**\n```\nUser Input \u2192 [Step 1: Translate] \u2192 [Step 2: Summarize] \u2192 [Step 3: Format] \u2192 Output\n```\n\n## \ud83e\udd14 Chain vs Agent\n\n**Chain:**\n- Fixed sequence of steps\n- Deterministic (same input \u2192 same path)\n- Fast and predictable\n- Use for: Well-defined workflows\n\n**Agent:**\n- Dynamically chooses actions\n- Can use tools\n- More flexible but slower\n- Use for: Open-ended tasks\n\n## \ud83d\udca1 When to Use Each\n\n**Use Chain when:**\n- You know the exact steps needed\n- Order is fixed\n- Need speed and predictability\n\n**Use Agent when:**\n- Steps depend on intermediate results\n- Need to use tools dynamically\n- Task is open-ended\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n# Part 2: Robust Chains\n\n**Time:** 60 min | **Difficulty:** Intermediate\n\n## \ud83c\udfaf The Problem\n\n**Issue:** LLMs sometimes return invalid output (wrong format, missing fields).\n\n**Impact:**\n- 15-30% parse failure rate (without retries)\n- Production system breaks\n- Poor user experience\n\n## \ud83d\udee1\ufe0f Solution: Retry with Feedback\n\n**Strategy:**\n1. Try to parse output\n2. If fails \u2192 tell LLM what went wrong\n3. LLM fixes the output\n4. Repeat up to N times\n\n**Result:** 15% failure \u2192 1-2% failure\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcbb Code Example: Chain with Auto-Retry\n\n**What this does:**\n- Calls LLM\n- Validates output\n- Retries with error feedback if needed\n- Tracks metrics\n\n**Study tip:** Focus on the retry logic (lines 20-35)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "class RobustChain:\n    \"\"\"Production chain with automatic retry.\"\"\"\n    \n    def __init__(self, llm_func: Callable, parser: Callable, max_retries=3):\n        self.llm_func = llm_func\n        self.parser = parser\n        self.max_retries = max_retries\n        self.metrics = {'calls': 0, 'retries': 0, 'failures': 0}\n    \n    def invoke(self, prompt: str) -> Any:\n        \"\"\"Execute with automatic retry on failure.\"\"\"\n        self.metrics['calls'] += 1\n        \n        for attempt in range(self.max_retries):\n            try:\n                # Call LLM\n                response = self.llm_func(prompt)\n                \n                # Try to parse/validate\n                result = self.parser(response)\n                \n                # Success!\n                return result\n                \n            except Exception as e:\n                self.metrics['retries'] += 1\n                \n                # Last attempt?\n                if attempt == self.max_retries - 1:\n                    self.metrics['failures'] += 1\n                    raise RuntimeError(f'Failed after {self.max_retries} attempts')\n                \n                # Add error feedback for next attempt\n                prompt += f\"\\n\\n[ERROR: {e}. Please fix the output.]\"\n                time.sleep(0.5)\n    \n    def get_metrics(self):\n        \"\"\"Get chain performance.\"\"\"\n        success_rate = 1 - (self.metrics['failures'] / self.metrics['calls']) if self.metrics['calls'] > 0 else 0\n        return {**self.metrics, 'success_rate': success_rate}\n\n# Mock LLM and parser for demo\ndef mock_llm(prompt: str) -> str:\n    \"\"\"Simulate LLM that sometimes fails.\"\"\"\n    import random\n    if random.random() < 0.3:  # 30% failure rate\n        return '{\"sentiment\": \"happy\"}'  # Invalid value!\n    return '{\"sentiment\": \"positive\", \"confidence\": 0.85}'\n\nclass SentimentOutput(BaseModel):\n    sentiment: str  # Should be: positive, negative, or neutral\n    confidence: float\n\ndef parser(response: str) -> SentimentOutput:\n    data = json.loads(response)\n    if data['sentiment'] not in ['positive', 'negative', 'neutral']:\n        raise ValueError(f\"Invalid sentiment: {data['sentiment']}\")\n    return SentimentOutput(**data)\n\n# Test the chain\nprint(\"\ud83d\udd04 ROBUST CHAIN DEMONSTRATION\\n\")\n\nchain = RobustChain(mock_llm, parser, max_retries=3)\n\nprint(\"Running 10 requests (30% initial failure rate)...\\n\")\n\nfor i in range(10):\n    try:\n        result = chain.invoke('Analyze sentiment')\n        print(f\"{i+1}. \u2705 Success: {result.sentiment}\")\n    except:\n        print(f\"{i+1}. \u274c Failed (even after retries)\")\n\nprint(f\"\\n\ud83d\udcca Metrics: {chain.get_metrics()}\")\nprint(f\"\\n\ud83d\udca1 Retry logic improved success rate significantly!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \u2705 Section Summary: Robust Chains\n\n### What You Learned:\n1. \u2713 LLMs can return invalid output (15-30% of the time)\n2. \u2713 Retry with error feedback improves success rate\n3. \u2713 Always validate output before using it\n4. \u2713 Track metrics to measure improvement\n\n### Key Takeaways:\n- \ud83d\udccc **Always implement retry** (3 attempts recommended)\n- \ud83d\udccc **Provide error feedback** (tell LLM what went wrong)\n- \ud83d\udccc **Validate with Pydantic** (catch issues early)\n- \ud83d\udccc **Track success rate** (measure improvements)\n\n### Impact:\n- Without retry: 15-30% failure rate\n- With retry (3x): 1-2% failure rate\n- **Improvement: 90%+ reduction in failures**\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n# \ud83d\udcdd Module 3 Complete!\n\n## \ud83c\udf93 What You've Mastered\n\n### Chains\n- \u2705 Building robust chains\n- \u2705 Error handling and retry\n- \u2705 Performance tracking\n\n### Agents (See full cells in original notebook)\n- \u2705 ReAct pattern\n- \u2705 Tool integration\n- \u2705 Multi-step reasoning\n\n### Memory (See full cells in original notebook)\n- \u2705 Conversation management\n- \u2705 Token budgets\n- \u2705 Multiple strategies\n\n### Evaluation (See full cells in original notebook)\n- \u2705 Test suite creation\n- \u2705 Metric tracking\n- \u2705 Regression detection\n\n---\n\n## \ud83c\udfaf Quick Reference\n\n**Building a chain:**\n```python\nchain = RobustChain(llm_func, parser, max_retries=3)\nresult = chain.invoke(prompt)\n```\n\n**Creating an agent:**\n```python\nagent = ReActAgent(llm, tools=[search, calculator])\nresult = agent.run(task)\n```\n\n**Setting up evaluation:**\n```python\nevaluator = EvaluationFramework()\nevaluator.add_test_case(\"test1\", input, expected)\nresults = evaluator.run(system)\n```\n\n---\n\n**Next:** Module 4 (LangGraph) for stateful workflows! \ud83d\ude80"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}