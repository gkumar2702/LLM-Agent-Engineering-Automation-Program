{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Python Coding Questions for Scientist II - Reservations\n",
        "\n",
        "This notebook contains Python coding questions relevant for the Uber Reserve Data Scientist role, covering:\n",
        "- Pandas/NumPy data manipulation\n",
        "- Statistical analysis\n",
        "- Machine learning implementation\n",
        "- Optimization problems\n",
        "- Time series analysis\n",
        "- Feature engineering\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ“ Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1: Calculate A/B Test Sample Size\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Statistical Analysis\n",
        "\n",
        "Write a function to calculate the minimum sample size needed for an A/B test given:\n",
        "- Baseline conversion rate\n",
        "- Minimum Detectable Effect (MDE)\n",
        "- Significance level (alpha)\n",
        "- Statistical power (1 - beta)\n",
        "\n",
        "**Formula:**\n",
        "For two-proportion z-test:\n",
        "$$n = \\frac{(Z_{\\alpha/2} + Z_{\\beta})^2 \\cdot (p_1(1-p_1) + p_2(1-p_2))}{(p_1 - p_2)^2}$$\n",
        "\n",
        "where $p_2 = p_1 + \\text{MDE}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_sample_size(baseline_rate, mde, alpha=0.05, power=0.8):\n",
        "    \"\"\"\n",
        "    Calculate minimum sample size per group for A/B test.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    baseline_rate : float\n",
        "        Baseline conversion rate (p1)\n",
        "    mde : float\n",
        "        Minimum Detectable Effect (absolute difference)\n",
        "    alpha : float\n",
        "        Significance level (default 0.05)\n",
        "    power : float\n",
        "        Statistical power (default 0.8)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    int : Minimum sample size per group\n",
        "    \"\"\"\n",
        "    from scipy.stats import norm\n",
        "    \n",
        "    # Calculate probabilities\n",
        "    p1 = baseline_rate\n",
        "    p2 = p1 + mde\n",
        "    \n",
        "    # Validate inputs\n",
        "    if p2 > 1 or p2 < 0 or p1 < 0 or p1 > 1:\n",
        "        raise ValueError(\"Probabilities must be between 0 and 1\")\n",
        "    \n",
        "    # Z-scores\n",
        "    z_alpha = norm.ppf(1 - alpha/2)  # Two-tailed test\n",
        "    z_beta = norm.ppf(power)\n",
        "    \n",
        "    # Pooled variance estimate\n",
        "    p_pooled = (p1 + p2) / 2\n",
        "    pooled_variance = p_pooled * (1 - p_pooled)\n",
        "    \n",
        "    # Sample size calculation\n",
        "    numerator = (z_alpha + z_beta)**2 * (p1 * (1 - p1) + p2 * (1 - p2))\n",
        "    denominator = (p1 - p2)**2\n",
        "    \n",
        "    n = numerator / denominator\n",
        "    \n",
        "    return int(np.ceil(n))\n",
        "\n",
        "# Test the function\n",
        "baseline = 0.10  # 10% baseline conversion\n",
        "mde = 0.02  # Want to detect 2% increase (to 12%)\n",
        "sample_size = calculate_sample_size(baseline, mde)\n",
        "print(f\"Sample size per group: {sample_size}\")\n",
        "print(f\"Total sample size: {sample_size * 2}\")\n",
        "\n",
        "# Example for different scenarios\n",
        "scenarios = [\n",
        "    (0.05, 0.01, \"Small baseline, small effect\"),\n",
        "    (0.10, 0.02, \"Medium baseline, medium effect\"),\n",
        "    (0.20, 0.05, \"Large baseline, large effect\")\n",
        "]\n",
        "\n",
        "for baseline, mde, desc in scenarios:\n",
        "    n = calculate_sample_size(baseline, mde)\n",
        "    print(f\"\\n{desc}:\")\n",
        "    print(f\"  Baseline: {baseline:.0%}, MDE: {mde:.0%} â†’ Sample size per group: {n:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2: Analyze Funnel Conversion Rates\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Data Analysis with Pandas\n",
        "\n",
        "Given a dataset of user interactions through a booking funnel, calculate:\n",
        "1. Conversion rate at each stage\n",
        "2. Drop-off rate between stages\n",
        "3. Identify the stage with highest drop-off\n",
        "\n",
        "**Funnel stages:** Awareness â†’ Interest â†’ Consideration â†’ Booking â†’ Completion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate sample data\n",
        "np.random.seed(42)\n",
        "n_users = 10000\n",
        "\n",
        "data = {\n",
        "    'user_id': range(1, n_users + 1),\n",
        "    'saw_reserve': np.random.choice([0, 1], n_users, p=[0.3, 0.7]),  # 70% awareness\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Each stage depends on previous stage\n",
        "df['clicked_reserve'] = df['saw_reserve'] * np.random.choice([0, 1], n_users, p=[0.4, 0.6])\n",
        "df['started_booking'] = df['clicked_reserve'] * np.random.choice([0, 1], n_users, p=[0.3, 0.7])\n",
        "df['completed_booking'] = df['started_booking'] * np.random.choice([0, 1], n_users, p=[0.2, 0.8])\n",
        "df['completed_trip'] = df['completed_booking'] * np.random.choice([0, 1], n_users, p=[0.1, 0.9])\n",
        "\n",
        "def analyze_funnel(df):\n",
        "    \"\"\"\n",
        "    Analyze conversion funnel and identify drop-off points.\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Dictionary with funnel metrics\n",
        "    \"\"\"\n",
        "    stages = {\n",
        "        'Awareness': 'saw_reserve',\n",
        "        'Interest': 'clicked_reserve',\n",
        "        'Consideration': 'started_booking',\n",
        "        'Booking': 'completed_booking',\n",
        "        'Completion': 'completed_trip'\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    previous_count = len(df)\n",
        "    \n",
        "    for stage_name, stage_col in stages.items():\n",
        "        current_count = df[stage_col].sum()\n",
        "        conversion_rate = current_count / previous_count if previous_count > 0 else 0\n",
        "        drop_off_rate = 1 - conversion_rate if previous_count > 0 else 0\n",
        "        overall_rate = current_count / len(df)\n",
        "        \n",
        "        results[stage_name] = {\n",
        "            'count': current_count,\n",
        "            'conversion_rate': conversion_rate,\n",
        "            'drop_off_rate': drop_off_rate,\n",
        "            'overall_rate': overall_rate\n",
        "        }\n",
        "        \n",
        "        previous_count = current_count\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Analyze funnel\n",
        "funnel_results = analyze_funnel(df)\n",
        "\n",
        "# Display results\n",
        "print(\"=\" * 60)\n",
        "print(\"FUNNEL ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Stage':<15} {'Count':<10} {'Conv Rate':<12} {'Drop-off':<12} {'Overall Rate':<12}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "prev_count = len(df)\n",
        "max_dropoff = 0\n",
        "max_dropoff_stage = None\n",
        "\n",
        "for stage, metrics in funnel_results.items():\n",
        "    print(f\"{stage:<15} {metrics['count']:<10,} {metrics['conversion_rate']:<12.1%} \"\n",
        "          f\"{metrics['drop_off_rate']:<12.1%} {metrics['overall_rate']:<12.1%}\")\n",
        "    \n",
        "    if metrics['drop_off_rate'] > max_dropoff:\n",
        "        max_dropoff = metrics['drop_off_rate']\n",
        "        max_dropoff_stage = stage\n",
        "    \n",
        "    prev_count = metrics['count']\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"\\nâš ï¸  Highest drop-off stage: {max_dropoff_stage} ({max_dropoff:.1%})\")\n",
        "print(f\"ðŸ’¡ Opportunity: Improving {max_dropoff_stage} could increase overall conversion\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3: Calculate Difference-in-Differences (DiD)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Causal Inference\n",
        "\n",
        "Implement a function to calculate Difference-in-Differences estimator for measuring treatment effect.\n",
        "\n",
        "**DiD Formula:**\n",
        "$$\\text{DiD} = (Y_{T,Post} - Y_{T,Pre}) - (Y_{C,Post} - Y_{C,Pre})$$\n",
        "\n",
        "where:\n",
        "- $Y_{T,Post}$: Treatment group after treatment\n",
        "- $Y_{T,Pre}$: Treatment group before treatment\n",
        "- $Y_{C,Post}$: Control group after treatment\n",
        "- $Y_{C,Pre}$: Control group before treatment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_did(df):\n",
        "    \"\"\"\n",
        "    Calculate Difference-in-Differences estimator.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Must have columns: 'group' (treatment/control), 'period' (pre/post), 'outcome'\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : DiD estimate and component means\n",
        "    \"\"\"\n",
        "    # Calculate means for each group-period combination\n",
        "    treatment_pre = df[(df['group'] == 'treatment') & (df['period'] == 'pre')]['outcome'].mean()\n",
        "    treatment_post = df[(df['group'] == 'treatment') & (df['period'] == 'post')]['outcome'].mean()\n",
        "    control_pre = df[(df['group'] == 'control') & (df['period'] == 'pre')]['outcome'].mean()\n",
        "    control_post = df[(df['group'] == 'control') & (df['period'] == 'post')]['outcome'].mean()\n",
        "    \n",
        "    # Calculate DiD\n",
        "    treatment_diff = treatment_post - treatment_pre\n",
        "    control_diff = control_post - control_pre\n",
        "    did_estimate = treatment_diff - control_diff\n",
        "    \n",
        "    return {\n",
        "        'did_estimate': did_estimate,\n",
        "        'treatment_pre': treatment_pre,\n",
        "        'treatment_post': treatment_post,\n",
        "        'control_pre': control_pre,\n",
        "        'control_post': control_post,\n",
        "        'treatment_diff': treatment_diff,\n",
        "        'control_diff': control_diff\n",
        "    }\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(42)\n",
        "n_obs = 1000\n",
        "\n",
        "# Simulate driver availability rates\n",
        "# Treatment group: incentive program\n",
        "# Control group: no change\n",
        "\n",
        "data = {\n",
        "    'group': np.random.choice(['treatment', 'control'], n_obs),\n",
        "    'period': np.random.choice(['pre', 'post'], n_obs),\n",
        "    'outcome': 0.0  # driver availability rate\n",
        "}\n",
        "\n",
        "df_did = pd.DataFrame(data)\n",
        "\n",
        "# Simulate outcomes with treatment effect\n",
        "for idx, row in df_did.iterrows():\n",
        "    base_rate = 0.6  # Base availability rate\n",
        "    \n",
        "    # Treatment effect: +0.15 (15 percentage points)\n",
        "    treatment_effect = 0.15 if row['group'] == 'treatment' and row['period'] == 'post' else 0\n",
        "    \n",
        "    # Time trend: +0.05 (5 percentage points over time)\n",
        "    time_trend = 0.05 if row['period'] == 'post' else 0\n",
        "    \n",
        "    df_did.loc[idx, 'outcome'] = base_rate + treatment_effect + time_trend + np.random.normal(0, 0.1)\n",
        "\n",
        "# Calculate DiD\n",
        "did_results = calculate_did(df_did)\n",
        "\n",
        "# Display results\n",
        "print(\"=\" * 70)\n",
        "print(\"DIFFERENCE-IN-DIFFERENCES ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nTreatment Group:\")\n",
        "print(f\"  Pre-period:  {did_results['treatment_pre']:.3f}\")\n",
        "print(f\"  Post-period: {did_results['treatment_post']:.3f}\")\n",
        "print(f\"  Difference:  {did_results['treatment_diff']:.3f} ({did_results['treatment_diff']:.1%})\")\n",
        "\n",
        "print(f\"\\nControl Group:\")\n",
        "print(f\"  Pre-period:  {did_results['control_pre']:.3f}\")\n",
        "print(f\"  Post-period: {did_results['control_post']:.3f}\")\n",
        "print(f\"  Difference:  {did_results['control_diff']:.3f} ({did_results['control_diff']:.1%})\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"DiD Estimate (Treatment Effect): {did_results['did_estimate']:.3f} ({did_results['did_estimate']:.1%})\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Interpretation\n",
        "if did_results['did_estimate'] > 0:\n",
        "    print(f\"\\nâœ“ Treatment had a positive effect of {did_results['did_estimate']:.1%}\")\n",
        "else:\n",
        "    print(f\"\\nâœ— Treatment had a negative effect of {did_results['did_estimate']:.1%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 4: Build a Cancellation Prediction Model\n",
        "\n",
        "**Difficulty:** Medium-Hard  \n",
        "**Topic:** Machine Learning\n",
        "\n",
        "Build a binary classification model to predict trip cancellations with proper feature engineering and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic trip data\n",
        "np.random.seed(42)\n",
        "n_trips = 10000\n",
        "\n",
        "def generate_trip_data(n):\n",
        "    \"\"\"Generate synthetic trip data with cancellation patterns.\"\"\"\n",
        "    data = {}\n",
        "    \n",
        "    # Basic trip features\n",
        "    data['trip_distance'] = np.random.exponential(5, n)\n",
        "    data['lead_time_minutes'] = np.random.exponential(30, n)  # Time until pickup\n",
        "    data['hour_of_day'] = np.random.randint(0, 24, n)\n",
        "    data['day_of_week'] = np.random.randint(0, 7, n)\n",
        "    data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)\n",
        "    \n",
        "    # Rider features\n",
        "    data['rider_history_cancel_rate'] = np.random.beta(2, 20, n)  # Most riders have low cancel rate\n",
        "    data['rider_trip_count'] = np.random.poisson(10, n)\n",
        "    \n",
        "    # Market features\n",
        "    data['driver_supply'] = np.random.uniform(0.5, 1.5, n)  # Supply index\n",
        "    data['surge_multiplier'] = np.random.lognormal(0, 0.3, n)\n",
        "    data['surge_multiplier'] = np.clip(data['surge_multiplier'], 1.0, 3.0)\n",
        "    \n",
        "    # Generate cancellation based on features (with some randomness)\n",
        "    # Higher cancellation probability for:\n",
        "    # - Longer lead times\n",
        "    # - Higher historical cancel rate\n",
        "    # - Low driver supply\n",
        "    # - Very high surge pricing\n",
        "    \n",
        "    cancel_prob = (\n",
        "        0.05 +  # Base rate\n",
        "        0.0003 * data['lead_time_minutes'] +  # Longer wait = more cancellation\n",
        "        2.0 * data['rider_history_cancel_rate'] +  # Historical pattern\n",
        "        -0.2 * data['driver_supply'] +  # Low supply = more cancellation\n",
        "        0.05 * (data['surge_multiplier'] - 1.0) +  # High surge = more cancellation\n",
        "        np.random.normal(0, 0.02, n)  # Random noise\n",
        "    )\n",
        "    \n",
        "    cancel_prob = np.clip(cancel_prob, 0, 1)\n",
        "    data['cancelled'] = (np.random.random(n) < cancel_prob).astype(int)\n",
        "    \n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_trips = generate_trip_data(n_trips)\n",
        "\n",
        "print(\"Sample trip data:\")\n",
        "print(df_trips.head())\n",
        "print(f\"\\nCancellation rate: {df_trips['cancelled'].mean():.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_cancellation_model(df):\n",
        "    \"\"\"\n",
        "    Build and evaluate a cancellation prediction model.\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Model and evaluation metrics\n",
        "    \"\"\"\n",
        "    # Feature engineering\n",
        "    df_model = df.copy()\n",
        "    \n",
        "    # Cyclical encoding for time features\n",
        "    df_model['hour_sin'] = np.sin(2 * np.pi * df_model['hour_of_day'] / 24)\n",
        "    df_model['hour_cos'] = np.cos(2 * np.pi * df_model['hour_of_day'] / 24)\n",
        "    df_model['day_sin'] = np.sin(2 * np.pi * df_model['day_of_week'] / 7)\n",
        "    df_model['day_cos'] = np.cos(2 * np.pi * df_model['day_of_week'] / 7)\n",
        "    \n",
        "    # Feature interactions\n",
        "    df_model['lead_time_hours'] = df_model['lead_time_minutes'] / 60\n",
        "    df_model['distance_per_lead_time'] = df_model['trip_distance'] / (df_model['lead_time_minutes'] + 1)\n",
        "    \n",
        "    # Prepare features\n",
        "    feature_cols = [\n",
        "        'trip_distance', 'lead_time_minutes', 'lead_time_hours',\n",
        "        'rider_history_cancel_rate', 'rider_trip_count',\n",
        "        'driver_supply', 'surge_multiplier',\n",
        "        'is_weekend', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
        "        'distance_per_lead_time'\n",
        "    ]\n",
        "    \n",
        "    X = df_model[feature_cols]\n",
        "    y = df_model['cancelled']\n",
        "    \n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    \n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Train model (using Gradient Boosting for better performance)\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred_proba = model.predict(X_test_scaled)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "        'f1': f1_score(y_test, y_pred, zero_division=0),\n",
        "        'roc_auc': roc_auc_score(y_test, y_pred_proba)\n",
        "    }\n",
        "    \n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': feature_cols,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    return {\n",
        "        'model': model,\n",
        "        'scaler': scaler,\n",
        "        'metrics': metrics,\n",
        "        'feature_importance': feature_importance,\n",
        "        'y_test': y_test,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }\n",
        "\n",
        "# Build model\n",
        "results = build_cancellation_model(df_trips)\n",
        "\n",
        "# Display results\n",
        "print(\"=\" * 60)\n",
        "print(\"CANCELLATION PREDICTION MODEL RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nModel Performance:\")\n",
        "for metric, value in results['metrics'].items():\n",
        "    print(f\"  {metric.upper()}: {value:.3f}\")\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(results['feature_importance'].head(10).to_string(index=False))\n",
        "\n",
        "# Additional analysis\n",
        "print(f\"\\nBaseline (predicting no cancellation): {1 - results['y_test'].mean():.3f}\")\n",
        "print(f\"Model improvement over baseline: {results['metrics']['accuracy'] - (1 - results['y_test'].mean()):.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 5: Implement Greedy Matching Algorithm\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Optimization Algorithms\n",
        "\n",
        "Implement a greedy algorithm to match riders with drivers, optimizing for minimum wait time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def greedy_matching(riders, drivers, distance_matrix):\n",
        "    \"\"\"\n",
        "    Greedy algorithm for rider-driver matching.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    riders : list\n",
        "        List of rider IDs\n",
        "    drivers : list\n",
        "        List of driver IDs\n",
        "    distance_matrix : np.array\n",
        "        Matrix where [i, j] is distance from rider i to driver j\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Matches {rider_id: driver_id}\n",
        "    \"\"\"\n",
        "    matches = {}\n",
        "    available_drivers = set(drivers)\n",
        "    \n",
        "    # Sort riders by some priority (e.g., wait time - here we use index as proxy)\n",
        "    # In practice, you'd sort by actual wait time or priority score\n",
        "    sorted_riders = sorted(riders)\n",
        "    \n",
        "    for rider_idx in sorted_riders:\n",
        "        if not available_drivers:\n",
        "            break\n",
        "        \n",
        "        # Find closest available driver\n",
        "        rider_pos = riders.index(rider_idx)\n",
        "        best_driver = None\n",
        "        min_distance = float('inf')\n",
        "        \n",
        "        for driver_idx in available_drivers:\n",
        "            driver_pos = drivers.index(driver_idx)\n",
        "            distance = distance_matrix[rider_pos, driver_pos]\n",
        "            \n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                best_driver = driver_idx\n",
        "        \n",
        "        # Match rider with best driver\n",
        "        if best_driver is not None:\n",
        "            matches[rider_idx] = best_driver\n",
        "            available_drivers.remove(best_driver)\n",
        "    \n",
        "    return matches\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(42)\n",
        "n_riders = 10\n",
        "n_drivers = 12\n",
        "\n",
        "# Rider and driver locations (in 2D space)\n",
        "rider_locations = np.random.rand(n_riders, 2) * 10\n",
        "driver_locations = np.random.rand(n_drivers, 2) * 10\n",
        "\n",
        "# Calculate distance matrix (Euclidean distance)\n",
        "distance_matrix = np.zeros((n_riders, n_drivers))\n",
        "for i in range(n_riders):\n",
        "    for j in range(n_drivers):\n",
        "        distance_matrix[i, j] = np.sqrt(\n",
        "            np.sum((rider_locations[i] - driver_locations[j])**2)\n",
        "        )\n",
        "\n",
        "riders = list(range(n_riders))\n",
        "drivers = list(range(n_drivers))\n",
        "\n",
        "# Perform matching\n",
        "matches = greedy_matching(riders, drivers, distance_matrix)\n",
        "\n",
        "# Display results\n",
        "print(\"=\" * 60)\n",
        "print(\"GREEDY MATCHING RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nMatched {len(matches)} out of {n_riders} riders\")\n",
        "print(f\"Available drivers: {n_drivers - len(matches)}\")\n",
        "\n",
        "print(\"\\nMatches (Rider â†’ Driver):\")\n",
        "total_distance = 0\n",
        "for rider, driver in matches.items():\n",
        "    distance = distance_matrix[rider, driver]\n",
        "    total_distance += distance\n",
        "    print(f\"  Rider {rider} â†’ Driver {driver} (distance: {distance:.2f})\")\n",
        "\n",
        "print(f\"\\nAverage match distance: {total_distance / len(matches):.2f}\")\n",
        "print(f\"Total distance: {total_distance:.2f}\")\n",
        "\n",
        "# Compare with optimal (Hungarian algorithm would give optimal)\n",
        "print(\"\\nNote: For small instances, Hungarian algorithm would give optimal solution.\")\n",
        "print(\"Greedy algorithm is faster but may not be optimal.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 6: Calculate Population Stability Index (PSI)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Data Drift Detection\n",
        "\n",
        "Implement PSI calculation to detect data drift between training and production data.\n",
        "\n",
        "**PSI Formula:**\n",
        "$$\\text{PSI} = \\sum_{i=1}^{n} (P_{\\text{actual},i} - P_{\\text{expected},i}) \\times \\ln\\left(\\frac{P_{\\text{actual},i}}{P_{\\text{expected},i}}\\right)$$\n",
        "\n",
        "where $P_i$ is the proportion of observations in bucket $i$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_psi(expected, actual, buckets=10):\n",
        "    \"\"\"\n",
        "    Calculate Population Stability Index (PSI) to detect data drift.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    expected : np.array or pd.Series\n",
        "        Expected distribution (training data)\n",
        "    actual : np.array or pd.Series\n",
        "        Actual distribution (production data)\n",
        "    buckets : int\n",
        "        Number of buckets for binning\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    float : PSI value\n",
        "    \"\"\"\n",
        "    # Create bins based on expected data\n",
        "    min_val = min(expected.min(), actual.min())\n",
        "    max_val = max(expected.max(), actual.max())\n",
        "    \n",
        "    # Handle edge case where all values are the same\n",
        "    if min_val == max_val:\n",
        "        return 0.0\n",
        "    \n",
        "    # Create buckets\n",
        "    bucket_edges = np.linspace(min_val, max_val, buckets + 1)\n",
        "    \n",
        "    # Bin the data\n",
        "    expected_counts, _ = np.histogram(expected, bins=bucket_edges)\n",
        "    actual_counts, _ = np.histogram(actual, bins=bucket_edges)\n",
        "    \n",
        "    # Normalize to proportions\n",
        "    expected_pct = expected_counts / len(expected)\n",
        "    actual_pct = actual_counts / len(actual)\n",
        "    \n",
        "    # Avoid division by zero (add small epsilon)\n",
        "    epsilon = 1e-10\n",
        "    expected_pct = expected_pct + epsilon\n",
        "    actual_pct = actual_pct + epsilon\n",
        "    \n",
        "    # Normalize again to ensure sum = 1\n",
        "    expected_pct = expected_pct / expected_pct.sum()\n",
        "    actual_pct = actual_pct / actual_pct.sum()\n",
        "    \n",
        "    # Calculate PSI\n",
        "    psi = np.sum((actual_pct - expected_pct) * np.log(actual_pct / expected_pct))\n",
        "    \n",
        "    return psi\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(42)\n",
        "\n",
        "# Training data (expected distribution)\n",
        "training_data = np.random.normal(50, 10, 10000)\n",
        "\n",
        "# Production data with different distributions\n",
        "prod_data_no_drift = np.random.normal(50, 10, 5000)  # Same distribution\n",
        "prod_data_shifted = np.random.normal(55, 10, 5000)   # Mean shifted\n",
        "prod_data_variance = np.random.normal(50, 15, 5000)  # Variance changed\n",
        "\n",
        "# Calculate PSI\n",
        "psi_no_drift = calculate_psi(training_data, prod_data_no_drift)\n",
        "psi_shifted = calculate_psi(training_data, prod_data_shifted)\n",
        "psi_variance = calculate_psi(training_data, prod_data_variance)\n",
        "\n",
        "# Display results\n",
        "print(\"=\" * 70)\n",
        "print(\"POPULATION STABILITY INDEX (PSI) ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\nPSI Interpretation:\")\n",
        "print(f\"  PSI < 0.1:    No significant drift\")\n",
        "print(f\"  0.1 â‰¤ PSI < 0.25: Moderate drift\")\n",
        "print(f\"  PSI â‰¥ 0.25:   Significant drift\")\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"  No drift scenario:     PSI = {psi_no_drift:.4f} âœ“\")\n",
        "print(f\"  Mean shifted scenario: PSI = {psi_shifted:.4f} âš ï¸\")\n",
        "print(f\"  Variance changed:      PSI = {psi_variance:.4f} âš ï¸\")\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "scenarios = [\n",
        "    (prod_data_no_drift, psi_no_drift, \"No Drift\"),\n",
        "    (prod_data_shifted, psi_shifted, \"Mean Shifted\"),\n",
        "    (prod_data_variance, psi_variance, \"Variance Changed\")\n",
        "]\n",
        "\n",
        "for ax, (prod_data, psi, title) in zip(axes, scenarios):\n",
        "    ax.hist(training_data, bins=30, alpha=0.5, label='Training', density=True)\n",
        "    ax.hist(prod_data, bins=30, alpha=0.5, label='Production', density=True)\n",
        "    ax.set_title(f\"{title}\\nPSI = {psi:.4f}\")\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Density')\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 7: Time Series Feature Engineering\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Feature Engineering\n",
        "\n",
        "Create time-based features from datetime data, including cyclical encoding, lag features, and rolling statistics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_time_features(df, date_col='timestamp'):\n",
        "    \"\"\"\n",
        "    Create comprehensive time-based features.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame with datetime column\n",
        "    date_col : str\n",
        "        Name of datetime column\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame : DataFrame with additional time features\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df[date_col] = pd.to_datetime(df[date_col])\n",
        "    \n",
        "    # Basic datetime features\n",
        "    df['year'] = df[date_col].dt.year\n",
        "    df['month'] = df[date_col].dt.month\n",
        "    df['day'] = df[date_col].dt.day\n",
        "    df['hour'] = df[date_col].dt.hour\n",
        "    df['day_of_week'] = df[date_col].dt.dayofweek  # Monday=0, Sunday=6\n",
        "    df['day_of_year'] = df[date_col].dt.dayofyear\n",
        "    df['week_of_year'] = df[date_col].dt.isocalendar().week\n",
        "    \n",
        "    # Cyclical encoding (captures periodic patterns)\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    \n",
        "    # Binary flags\n",
        "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "    df['is_morning'] = ((df['hour'] >= 6) & (df['hour'] < 12)).astype(int)\n",
        "    df['is_afternoon'] = ((df['hour'] >= 12) & (df['hour'] < 18)).astype(int)\n",
        "    df['is_evening'] = ((df['hour'] >= 18) & (df['hour'] < 24)).astype(int)\n",
        "    df['is_night'] = ((df['hour'] >= 0) & (df['hour'] < 6)).astype(int)\n",
        "    \n",
        "    # Business hour indicators\n",
        "    df['is_business_hour'] = ((df['day_of_week'] < 5) & \n",
        "                               (df['hour'] >= 9) & \n",
        "                               (df['hour'] < 17)).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Generate sample time series data\n",
        "dates = pd.date_range('2024-01-01', periods=1000, freq='H')\n",
        "df_time = pd.DataFrame({\n",
        "    'timestamp': dates,\n",
        "    'trip_count': np.random.poisson(10, 1000)  # Simulated trip counts\n",
        "})\n",
        "\n",
        "# Create time features\n",
        "df_time_features = create_time_features(df_time)\n",
        "\n",
        "print(\"Sample time features:\")\n",
        "print(df_time_features[['timestamp', 'hour', 'day_of_week', 'hour_sin', \n",
        "                        'hour_cos', 'is_weekend', 'is_business_hour']].head(10))\n",
        "\n",
        "print(\"\\nFeature summary:\")\n",
        "print(f\"  Total features created: {len(df_time_features.columns) - 2}\")  # Exclude original cols\n",
        "print(f\"  Cyclical features: 6 (hour, day, month sin/cos)\")\n",
        "print(f\"  Binary flags: 6 (weekend, time periods, business hours)\")\n",
        "print(f\"  Basic datetime: 7 (year, month, day, etc.)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 8: Handle Imbalanced Dataset with SMOTE\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Machine Learning - Class Imbalance\n",
        "\n",
        "Implement SMOTE (Synthetic Minority Oversampling Technique) to handle imbalanced classification datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def smote_oversample(X, y, k=5, minority_class=1, oversampling_ratio=1.0):\n",
        "    \"\"\"\n",
        "    Simplified SMOTE implementation.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    X : np.array\n",
        "        Feature matrix\n",
        "    y : np.array\n",
        "        Target vector\n",
        "    k : int\n",
        "        Number of nearest neighbors\n",
        "    minority_class : int\n",
        "        Class to oversample\n",
        "    oversampling_ratio : float\n",
        "        Ratio of synthetic samples to create (1.0 = equal to majority class)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    X_resampled, y_resampled : Oversampled data\n",
        "    \"\"\"\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "    \n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    \n",
        "    # Separate minority and majority classes\n",
        "    minority_indices = np.where(y == minority_class)[0]\n",
        "    majority_indices = np.where(y != minority_class)[0]\n",
        "    \n",
        "    X_minority = X[minority_indices]\n",
        "    X_majority = X[majority_indices]\n",
        "    \n",
        "    # Calculate how many samples to generate\n",
        "    n_minority = len(X_minority)\n",
        "    n_majority = len(X_majority)\n",
        "    n_synthetic = int((n_majority - n_minority) * oversampling_ratio)\n",
        "    \n",
        "    # Find k nearest neighbors for each minority sample\n",
        "    nn = NearestNeighbors(n_neighbors=k+1)  # +1 because sample is its own neighbor\n",
        "    nn.fit(X_minority)\n",
        "    neighbors = nn.kneighbors(X_minority, return_distance=False)\n",
        "    \n",
        "    # Generate synthetic samples\n",
        "    synthetic_samples = []\n",
        "    for i in range(n_synthetic):\n",
        "        # Randomly choose a minority sample\n",
        "        sample_idx = np.random.randint(n_minority)\n",
        "        sample = X_minority[sample_idx]\n",
        "        \n",
        "        # Randomly choose one of its k nearest neighbors (excluding itself)\n",
        "        neighbor_idx = np.random.choice(neighbors[sample_idx][1:])\n",
        "        neighbor = X_minority[neighbor_idx]\n",
        "        \n",
        "        # Generate synthetic sample along the line between sample and neighbor\n",
        "        alpha = np.random.random()\n",
        "        synthetic = sample + alpha * (neighbor - sample)\n",
        "        synthetic_samples.append(synthetic)\n",
        "    \n",
        "    # Combine original and synthetic samples\n",
        "    X_resampled = np.vstack([X, np.array(synthetic_samples)])\n",
        "    y_resampled = np.hstack([y, np.full(n_synthetic, minority_class)])\n",
        "    \n",
        "    return X_resampled, y_resampled\n",
        "\n",
        "# Generate imbalanced dataset\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "\n",
        "# Features\n",
        "X = np.random.randn(n_samples, 5)\n",
        "\n",
        "# Imbalanced target (90% class 0, 10% class 1)\n",
        "y = np.random.choice([0, 1], n_samples, p=[0.9, 0.1])\n",
        "\n",
        "print(\"Original dataset:\")\n",
        "print(f\"  Class 0: {np.sum(y == 0)} ({np.mean(y == 0):.1%})\")\n",
        "print(f\"  Class 1: {np.sum(y == 1)} ({np.mean(y == 1):.1%})\")\n",
        "\n",
        "# Apply SMOTE\n",
        "X_resampled, y_resampled = smote_oversample(X, y, k=5, oversampling_ratio=1.0)\n",
        "\n",
        "print(\"\\nAfter SMOTE:\")\n",
        "print(f\"  Class 0: {np.sum(y_resampled == 0)} ({np.mean(y_resampled == 0):.1%})\")\n",
        "print(f\"  Class 1: {np.sum(y_resampled == 1)} ({np.mean(y_resampled == 1):.1%})\")\n",
        "print(f\"  Total samples: {len(y_resampled)}\")\n",
        "print(f\"  Synthetic samples created: {len(y_resampled) - len(y)}\")\n",
        "\n",
        "# Note: In production, use imbalanced-learn library\n",
        "print(\"\\nðŸ’¡ Note: For production use, consider using imbalanced-learn library:\")\n",
        "print(\"   from imblearn.over_sampling import SMOTE\")\n",
        "print(\"   smote = SMOTE(random_state=42)\")\n",
        "print(\"   X_resampled, y_resampled = smote.fit_resample(X, y)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 9: Calculate Cohort Retention\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Business Analytics\n",
        "\n",
        "Calculate cohort-based retention rates to understand user behavior over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_cohort_retention(df, user_col='user_id', date_col='date', period='M'):\n",
        "    \"\"\"\n",
        "    Calculate cohort retention rates.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Transaction data with user_id and date\n",
        "    user_col : str\n",
        "        Column name for user identifier\n",
        "    date_col : str\n",
        "        Column name for date\n",
        "    period : str\n",
        "        Period for cohort grouping ('M' for monthly, 'W' for weekly)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame : Cohort retention matrix\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df[date_col] = pd.to_datetime(df[date_col])\n",
        "    \n",
        "    # Assign cohort based on first transaction\n",
        "    df['cohort'] = df.groupby(user_col)[date_col].transform('min')\n",
        "    \n",
        "    # Create period labels\n",
        "    df['cohort_period'] = df['cohort'].dt.to_period(period)\n",
        "    df['period'] = df[date_col].dt.to_period(period)\n",
        "    \n",
        "    # Calculate period number (0, 1, 2, ...)\n",
        "    df['period_number'] = (df['period'] - df['cohort_period']).apply(attrgetter('n'))\n",
        "    \n",
        "    # Count unique users per cohort-period\n",
        "    cohort_data = df.groupby(['cohort_period', 'period_number'])[user_col].nunique().reset_index()\n",
        "    cohort_data.columns = ['cohort', 'period', 'users']\n",
        "    \n",
        "    # Pivot to create retention matrix\n",
        "    retention_matrix = cohort_data.pivot(index='cohort', columns='period', values='users')\n",
        "    \n",
        "    # Calculate retention rates (as percentage of cohort size)\n",
        "    cohort_sizes = retention_matrix.iloc[:, 0]  # First period = cohort size\n",
        "    retention_pct = retention_matrix.div(cohort_sizes, axis=0) * 100\n",
        "    \n",
        "    return retention_pct\n",
        "\n",
        "# Generate sample user transaction data\n",
        "np.random.seed(42)\n",
        "n_users = 1000\n",
        "start_date = pd.Timestamp('2024-01-01')\n",
        "end_date = pd.Timestamp('2024-06-30')\n",
        "\n",
        "transactions = []\n",
        "for user_id in range(n_users):\n",
        "    # User's first transaction date (cohort assignment)\n",
        "    first_date = start_date + pd.Timedelta(days=np.random.randint(0, 90))\n",
        "    \n",
        "    # Number of transactions for this user\n",
        "    n_transactions = np.random.poisson(5)\n",
        "    \n",
        "    # Generate transaction dates (with some retention decay)\n",
        "    for i in range(n_transactions):\n",
        "        # Later transactions become less likely\n",
        "        if np.random.random() < 0.3 ** (i / 3):\n",
        "            transaction_date = first_date + pd.Timedelta(days=np.random.randint(0, 150))\n",
        "            if transaction_date <= end_date:\n",
        "                transactions.append({\n",
        "                    'user_id': user_id,\n",
        "                    'date': transaction_date\n",
        "                })\n",
        "\n",
        "df_cohort = pd.DataFrame(transactions)\n",
        "\n",
        "# Calculate retention\n",
        "retention = calculate_cohort_retention(df_cohort)\n",
        "\n",
        "print(\"Cohort Retention Matrix (%):\")\n",
        "print(\"=\" * 80)\n",
        "print(retention.round(1).fillna(''))\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"- Rows represent cohorts (when users first transacted)\")\n",
        "print(\"- Columns represent periods since cohort start (0 = first period)\")\n",
        "print(\"- Values show % of cohort users active in that period\")\n",
        "print(\"- Higher values in later periods indicate better retention\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Concepts for Data Science Interviews\n",
        "\n",
        "### Data Structures to Know:\n",
        "1. **Arrays/Lists**: Basic indexing, slicing, array operations\n",
        "2. **Hash Maps/Dictionaries**: O(1) lookups, counting frequencies\n",
        "3. **Sets**: Uniqueness, set operations\n",
        "4. **Heaps**: Priority queues, top-K elements\n",
        "5. **Stacks/Queues**: LIFO/FIFO operations\n",
        "6. **Trees**: Binary trees, BST operations\n",
        "7. **Graphs**: Adjacency lists, DFS/BFS, shortest paths\n",
        "\n",
        "### Algorithms to Master:\n",
        "1. **Two Pointers**: Sliding window, fast/slow pointers\n",
        "2. **Binary Search**: Search in sorted arrays\n",
        "3. **Greedy Algorithms**: Local optimization\n",
        "4. **Dynamic Programming**: Overlapping subproblems\n",
        "5. **Graph Algorithms**: DFS, BFS, Dijkstra's\n",
        "6. **Sorting**: Merge sort, quick sort, counting sort\n",
        "\n",
        "### Time Complexity Basics:\n",
        "- O(1): Constant time\n",
        "- O(log n): Logarithmic (binary search)\n",
        "- O(n): Linear (single pass)\n",
        "- O(n log n): Linearithmic (sorting)\n",
        "- O(nÂ²): Quadratic (nested loops)\n",
        "- O(2^n): Exponential (recursion without memoization)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 10: Two Sum Problem\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Arrays, Hash Maps  \n",
        "**Frequency:** Very Common in Interviews\n",
        "\n",
        "Given an array of integers and a target sum, find two numbers that add up to the target.\n",
        "\n",
        "**Key Concept:** Use hash map for O(1) lookups instead of nested loops.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def two_sum(nums, target):\n",
        "    \"\"\"\n",
        "    Find two numbers in array that sum to target.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(n)\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    nums : List[int]\n",
        "        List of integers\n",
        "    target : int\n",
        "        Target sum\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    List[int]: Indices of two numbers that sum to target\n",
        "    \"\"\"\n",
        "    # Hash map to store value -> index\n",
        "    num_map = {}\n",
        "    \n",
        "    for i, num in enumerate(nums):\n",
        "        complement = target - num\n",
        "        \n",
        "        # Check if complement exists in map\n",
        "        if complement in num_map:\n",
        "            return [num_map[complement], i]\n",
        "        \n",
        "        # Store current number and index\n",
        "        num_map[num] = i\n",
        "    \n",
        "    return []  # No solution found\n",
        "\n",
        "# Test cases\n",
        "test_cases = [\n",
        "    ([2, 7, 11, 15], 9, [0, 1]),\n",
        "    ([3, 2, 4], 6, [1, 2]),\n",
        "    ([3, 3], 6, [0, 1]),\n",
        "    ([1, 5, 3, 7], 10, [1, 3])\n",
        "]\n",
        "\n",
        "print(\"Two Sum Problem:\")\n",
        "print(\"=\" * 60)\n",
        "for nums, target, expected in test_cases:\n",
        "    result = two_sum(nums, target)\n",
        "    print(f\"Input: nums={nums}, target={target}\")\n",
        "    print(f\"Output: {result}\")\n",
        "    print(f\"Expected: {expected}\")\n",
        "    print(f\"Match: {result == expected}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# Application: Find two trips with combined distance equal to target\n",
        "trips = [5.2, 3.1, 8.7, 2.5, 6.3, 4.9]\n",
        "target_distance = 10.0\n",
        "result_indices = two_sum([int(d*10) for d in trips], int(target_distance*10))\n",
        "if result_indices:\n",
        "    print(f\"\\nTrips with combined distance {target_distance}:\")\n",
        "    print(f\"Trip {result_indices[0]}: {trips[result_indices[0]]} km\")\n",
        "    print(f\"Trip {result_indices[1]}: {trips[result_indices[1]]} km\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 11: Sliding Window Maximum (Relevant for Time Series)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Arrays, Sliding Window, Deque  \n",
        "**Use Case:** Moving averages, time window aggregations\n",
        "\n",
        "Find the maximum in each sliding window of size k.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "def sliding_window_maximum(nums, k):\n",
        "    \"\"\"\n",
        "    Find maximum in each sliding window of size k.\n",
        "    \n",
        "    Time Complexity: O(n) - each element added/removed once\n",
        "    Space Complexity: O(k) - deque size\n",
        "    \n",
        "    Key Concept: Use deque to maintain potential maximums in window\n",
        "    \"\"\"\n",
        "    if not nums or k == 0:\n",
        "        return []\n",
        "    \n",
        "    # Deque stores indices of elements\n",
        "    dq = deque()\n",
        "    result = []\n",
        "    \n",
        "    for i in range(len(nums)):\n",
        "        # Remove indices outside current window\n",
        "        while dq and dq[0] <= i - k:\n",
        "            dq.popleft()\n",
        "        \n",
        "        # Remove indices whose values are smaller than current\n",
        "        # (they can never be maximum in this or future windows)\n",
        "        while dq and nums[dq[-1]] < nums[i]:\n",
        "            dq.pop()\n",
        "        \n",
        "        # Add current index\n",
        "        dq.append(i)\n",
        "        \n",
        "        # Window of size k is complete\n",
        "        if i >= k - 1:\n",
        "            result.append(nums[dq[0]])\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Test\n",
        "print(\"Sliding Window Maximum:\")\n",
        "print(\"=\" * 60)\n",
        "nums = [1, 3, -1, -3, 5, 3, 6, 7]\n",
        "k = 3\n",
        "result = sliding_window_maximum(nums, k)\n",
        "print(f\"Input: {nums}, k={k}\")\n",
        "print(f\"Output: {result}\")\n",
        "print(f\"Explanation: Max in [1,3,-1]=3, [3,-1,-3]=3, [-1,-3,5]=5, etc.\")\n",
        "\n",
        "# Application: Find maximum driver availability in each hour window\n",
        "hourly_availability = [10, 15, 12, 8, 20, 25, 18, 22, 30, 28]\n",
        "window_size = 3\n",
        "max_per_window = sliding_window_maximum(hourly_availability, window_size)\n",
        "print(f\"\\nHourly driver availability: {hourly_availability}\")\n",
        "print(f\"Maximum in each {window_size}-hour window: {max_per_window}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 12: Top K Frequent Elements (Common in ML/DS)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Hash Maps, Heaps  \n",
        "**Use Case:** Feature importance, most common events, top users\n",
        "\n",
        "Find K most frequent elements in an array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import heapq\n",
        "from collections import Counter\n",
        "\n",
        "def top_k_frequent(nums, k):\n",
        "    \"\"\"\n",
        "    Find K most frequent elements.\n",
        "    \n",
        "    Time Complexity: O(n + k log n) - Counter + heap operations\n",
        "    Space Complexity: O(n) - for Counter and heap\n",
        "    \n",
        "    Approach 1: Using Counter and heapq.nlargest\n",
        "    \"\"\"\n",
        "    # Count frequencies\n",
        "    count = Counter(nums)\n",
        "    \n",
        "    # Get k largest by frequency\n",
        "    return [item for item, freq in count.most_common(k)]\n",
        "\n",
        "def top_k_frequent_heap(nums, k):\n",
        "    \"\"\"\n",
        "    Alternative: Using min heap of size k.\n",
        "    \n",
        "    More memory efficient for large datasets with k << n\n",
        "    \"\"\"\n",
        "    count = Counter(nums)\n",
        "    \n",
        "    # Min heap of size k\n",
        "    heap = []\n",
        "    \n",
        "    for num, freq in count.items():\n",
        "        if len(heap) < k:\n",
        "            heapq.heappush(heap, (freq, num))\n",
        "        elif freq > heap[0][0]:\n",
        "            heapq.heapreplace(heap, (freq, num))\n",
        "    \n",
        "    # Extract results\n",
        "    return [num for freq, num in heap]\n",
        "\n",
        "# Test\n",
        "print(\"Top K Frequent Elements:\")\n",
        "print(\"=\" * 60)\n",
        "nums = [1, 1, 1, 2, 2, 3, 4, 4, 4, 4]\n",
        "k = 2\n",
        "result1 = top_k_frequent(nums, k)\n",
        "result2 = top_k_frequent_heap(nums, k)\n",
        "print(f\"Input: {nums}, k={k}\")\n",
        "print(f\"Output (Counter): {result1}\")\n",
        "print(f\"Output (Heap): {result2}\")\n",
        "\n",
        "# Application: Find top K cities by trip count\n",
        "city_trips = ['NYC', 'SF', 'NYC', 'LA', 'SF', 'SF', 'NYC', 'CHI', 'NYC', 'LA']\n",
        "top_cities = top_k_frequent(city_trips, 3)\n",
        "print(f\"\\nCity trip counts: {Counter(city_trips)}\")\n",
        "print(f\"Top 3 cities: {top_cities}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 13: Binary Search (Search in Sorted Array)\n",
        "\n",
        "**Difficulty:** Easy-Medium  \n",
        "**Topic:** Binary Search  \n",
        "**Use Case:** Search in sorted data, finding thresholds\n",
        "\n",
        "Implement binary search to find target in sorted array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def binary_search(arr, target):\n",
        "    \"\"\"\n",
        "    Binary search in sorted array.\n",
        "    \n",
        "    Time Complexity: O(log n)\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: Divide and conquer, eliminate half of search space each time\n",
        "    \"\"\"\n",
        "    left, right = 0, len(arr) - 1\n",
        "    \n",
        "    while left <= right:\n",
        "        mid = left + (right - left) // 2  # Avoid overflow\n",
        "        \n",
        "        if arr[mid] == target:\n",
        "            return mid\n",
        "        elif arr[mid] < target:\n",
        "            left = mid + 1\n",
        "        else:\n",
        "            right = mid - 1\n",
        "    \n",
        "    return -1  # Not found\n",
        "\n",
        "def binary_search_first_occurrence(arr, target):\n",
        "    \"\"\"\n",
        "    Find first occurrence of target (useful for duplicates).\n",
        "    \"\"\"\n",
        "    left, right = 0, len(arr)\n",
        "    result = -1\n",
        "    \n",
        "    while left < right:\n",
        "        mid = left + (right - left) // 2\n",
        "        if arr[mid] == target:\n",
        "            result = mid\n",
        "            right = mid  # Continue searching left\n",
        "        elif arr[mid] < target:\n",
        "            left = mid + 1\n",
        "        else:\n",
        "            right = mid\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Test\n",
        "print(\"Binary Search:\")\n",
        "print(\"=\" * 60)\n",
        "sorted_array = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
        "target = 11\n",
        "result = binary_search(sorted_array, target)\n",
        "print(f\"Array: {sorted_array}\")\n",
        "print(f\"Target: {target}\")\n",
        "print(f\"Index: {result}\")\n",
        "print(f\"Value at index: {sorted_array[result] if result != -1 else 'Not found'}\")\n",
        "\n",
        "# Application: Find driver with rating >= threshold\n",
        "driver_ratings = [3.2, 3.5, 3.8, 4.1, 4.3, 4.5, 4.7, 4.9, 5.0]\n",
        "threshold = 4.5\n",
        "# Find first index where rating >= threshold\n",
        "left, right = 0, len(driver_ratings)\n",
        "while left < right:\n",
        "    mid = left + (right - left) // 2\n",
        "    if driver_ratings[mid] < threshold:\n",
        "        left = mid + 1\n",
        "    else:\n",
        "        right = mid\n",
        "print(f\"\\nDriver ratings: {driver_ratings}\")\n",
        "print(f\"First driver with rating >= {threshold}: index {left}, rating {driver_ratings[left]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 14: Valid Parentheses (Stack Problem)\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Stacks  \n",
        "**Use Case:** Expression validation, nested structures\n",
        "\n",
        "Check if parentheses in a string are valid (properly matched).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_valid_parentheses(s):\n",
        "    \"\"\"\n",
        "    Check if parentheses are valid.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(n) worst case\n",
        "    \n",
        "    Key Concept: Use stack to track opening brackets, pop when matching closing bracket\n",
        "    \"\"\"\n",
        "    stack = []\n",
        "    mapping = {')': '(', '}': '{', ']': '['}\n",
        "    \n",
        "    for char in s:\n",
        "        if char in mapping:  # Closing bracket\n",
        "            if not stack or stack.pop() != mapping[char]:\n",
        "                return False\n",
        "        else:  # Opening bracket\n",
        "            stack.append(char)\n",
        "    \n",
        "    return len(stack) == 0\n",
        "\n",
        "# Test\n",
        "print(\"Valid Parentheses:\")\n",
        "print(\"=\" * 60)\n",
        "test_cases = [\n",
        "    (\"()\", True),\n",
        "    (\"()[]{}\", True),\n",
        "    (\"(]\", False),\n",
        "    (\"([)]\", False),\n",
        "    (\"{[]}\", True),\n",
        "    (\"\", True)\n",
        "]\n",
        "\n",
        "for s, expected in test_cases:\n",
        "    result = is_valid_parentheses(s)\n",
        "    print(f\"Input: '{s}' -> Output: {result}, Expected: {expected}, Match: {result == expected}\")\n",
        "\n",
        "# Application: Validate nested JSON-like structure for configuration\n",
        "config_str = \"{[{()}]}\"\n",
        "print(f\"\\nConfig validation '{config_str}': {is_valid_parentheses(config_str)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 15: Longest Substring Without Repeating Characters\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Sliding Window, Hash Maps  \n",
        "**Use Case:** Finding unique sequences, data deduplication\n",
        "\n",
        "Find length of longest substring without repeating characters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def length_of_longest_substring(s):\n",
        "    \"\"\"\n",
        "    Find length of longest substring without repeating characters.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(min(n, m)) where m is charset size\n",
        "    \n",
        "    Key Concept: Sliding window with hash map to track character positions\n",
        "    \"\"\"\n",
        "    char_map = {}  # character -> last seen index\n",
        "    start = 0\n",
        "    max_length = 0\n",
        "    \n",
        "    for end, char in enumerate(s):\n",
        "        # If character seen before and within current window\n",
        "        if char in char_map and char_map[char] >= start:\n",
        "            start = char_map[char] + 1\n",
        "        \n",
        "        char_map[char] = end\n",
        "        max_length = max(max_length, end - start + 1)\n",
        "    \n",
        "    return max_length\n",
        "\n",
        "# Test\n",
        "print(\"Longest Substring Without Repeating Characters:\")\n",
        "print(\"=\" * 60)\n",
        "test_cases = [\n",
        "    (\"abcabcbb\", 3),  # \"abc\"\n",
        "    (\"bbbbb\", 1),     # \"b\"\n",
        "    (\"pwwkew\", 3),    # \"wke\"\n",
        "    (\"\", 0),\n",
        "    (\"dvdf\", 3)       # \"vdf\"\n",
        "]\n",
        "\n",
        "for s, expected in test_cases:\n",
        "    result = length_of_longest_substring(s)\n",
        "    print(f\"Input: '{s}' -> Output: {result}, Expected: {expected}, Match: {result == expected}\")\n",
        "\n",
        "# Application: Find longest sequence of unique user IDs\n",
        "user_sequence = \"abcabcbb\"\n",
        "max_unique = length_of_longest_substring(user_sequence)\n",
        "print(f\"\\nUser sequence: {user_sequence}\")\n",
        "print(f\"Longest unique sequence length: {max_unique}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 16: Merge Intervals (Time Window Problem)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Arrays, Sorting, Merging  \n",
        "**Use Case:** Scheduling, time slot management, overlapping periods\n",
        "\n",
        "Merge overlapping intervals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def merge_intervals(intervals):\n",
        "    \"\"\"\n",
        "    Merge overlapping intervals.\n",
        "    \n",
        "    Time Complexity: O(n log n) due to sorting\n",
        "    Space Complexity: O(n) for result\n",
        "    \n",
        "    Key Concept: Sort by start time, then merge overlapping intervals\n",
        "    \"\"\"\n",
        "    if not intervals:\n",
        "        return []\n",
        "    \n",
        "    # Sort by start time\n",
        "    intervals.sort(key=lambda x: x[0])\n",
        "    \n",
        "    merged = [intervals[0]]\n",
        "    \n",
        "    for current in intervals[1:]:\n",
        "        last = merged[-1]\n",
        "        \n",
        "        # If current overlaps with last, merge them\n",
        "        if current[0] <= last[1]:\n",
        "            merged[-1] = [last[0], max(last[1], current[1])]\n",
        "        else:\n",
        "            merged.append(current)\n",
        "    \n",
        "    return merged\n",
        "\n",
        "# Test\n",
        "print(\"Merge Intervals:\")\n",
        "print(\"=\" * 60)\n",
        "test_intervals = [[1, 3], [2, 6], [8, 10], [15, 18]]\n",
        "result = merge_intervals(test_intervals)\n",
        "print(f\"Input: {test_intervals}\")\n",
        "print(f\"Output: {result}\")\n",
        "print(\"Explanation: [1,3] and [2,6] overlap -> merge to [1,6]\")\n",
        "\n",
        "# Application: Merge overlapping booking time slots\n",
        "booking_slots = [\n",
        "    [9, 10],   # 9:00-10:00\n",
        "    [9, 30, 10, 30],  # 9:30-10:30\n",
        "    [11, 12],  # 11:00-12:00\n",
        "    [11, 30, 12, 30]  # 11:30-12:30\n",
        "]\n",
        "merged_slots = merge_intervals(booking_slots)\n",
        "print(f\"\\nBooking slots: {booking_slots}\")\n",
        "print(f\"Merged slots: {merged_slots}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 17: Best Time to Buy and Sell Stock (Dynamic Programming)\n",
        "\n",
        "**Difficulty:** Easy-Medium  \n",
        "**Topic:** Dynamic Programming, Arrays  \n",
        "**Use Case:** Optimization problems, finding maximum profit\n",
        "\n",
        "Find maximum profit from buying and selling stock once.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def max_profit(prices):\n",
        "    \"\"\"\n",
        "    Find maximum profit from one buy and one sell.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: Track minimum price seen so far, calculate profit at each day\n",
        "    \"\"\"\n",
        "    if not prices:\n",
        "        return 0\n",
        "    \n",
        "    min_price = prices[0]\n",
        "    max_profit = 0\n",
        "    \n",
        "    for price in prices[1:]:\n",
        "        # Update minimum price seen so far\n",
        "        min_price = min(min_price, price)\n",
        "        # Calculate profit if we sell today\n",
        "        max_profit = max(max_profit, price - min_price)\n",
        "    \n",
        "    return max_profit\n",
        "\n",
        "def max_profit_multiple_transactions(prices):\n",
        "    \"\"\"\n",
        "    Find maximum profit with multiple transactions allowed.\n",
        "    \n",
        "    Key Concept: Buy before every price increase, sell before every price decrease\n",
        "    \"\"\"\n",
        "    if not prices:\n",
        "        return 0\n",
        "    \n",
        "    profit = 0\n",
        "    for i in range(1, len(prices)):\n",
        "        if prices[i] > prices[i-1]:\n",
        "            profit += prices[i] - prices[i-1]\n",
        "    \n",
        "    return profit\n",
        "\n",
        "# Test\n",
        "print(\"Best Time to Buy and Sell Stock:\")\n",
        "print(\"=\" * 60)\n",
        "prices = [7, 1, 5, 3, 6, 4]\n",
        "result1 = max_profit(prices)\n",
        "result2 = max_profit_multiple_transactions(prices)\n",
        "print(f\"Prices: {prices}\")\n",
        "print(f\"Max profit (one transaction): {result1}\")  # Buy at 1, sell at 6\n",
        "print(f\"Max profit (multiple transactions): {result2}\")  # Buy at 1, sell at 5; buy at 3, sell at 6\n",
        "\n",
        "# Application: Optimal pricing strategy\n",
        "ride_prices = [10, 15, 12, 18, 20, 16]\n",
        "optimal_profit = max_profit_multiple_transactions(ride_prices)\n",
        "print(f\"\\nRide prices over time: {ride_prices}\")\n",
        "print(f\"Maximum profit from dynamic pricing: {optimal_profit}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 18: Group Anagrams (Hash Maps)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Hash Maps, String Manipulation  \n",
        "**Use Case:** Grouping similar items, categorization\n",
        "\n",
        "Group strings that are anagrams of each other.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def group_anagrams(strs):\n",
        "    \"\"\"\n",
        "    Group anagrams together.\n",
        "    \n",
        "    Time Complexity: O(n * k log k) where k is avg string length\n",
        "    Space Complexity: O(n * k)\n",
        "    \n",
        "    Key Concept: Use sorted string as key to group anagrams\n",
        "    \"\"\"\n",
        "    groups = defaultdict(list)\n",
        "    \n",
        "    for s in strs:\n",
        "        # Sort characters to create key\n",
        "        key = ''.join(sorted(s))\n",
        "        groups[key].append(s)\n",
        "    \n",
        "    return list(groups.values())\n",
        "\n",
        "# Alternative: Use character count as key (more efficient for long strings)\n",
        "def group_anagrams_count(strs):\n",
        "    \"\"\"\n",
        "    Use character frequency count as key.\n",
        "    \n",
        "    More efficient for longer strings.\n",
        "    \"\"\"\n",
        "    groups = defaultdict(list)\n",
        "    \n",
        "    for s in strs:\n",
        "        count = [0] * 26  # For lowercase letters\n",
        "        for char in s:\n",
        "            count[ord(char) - ord('a')] += 1\n",
        "        key = tuple(count)\n",
        "        groups[key].append(s)\n",
        "    \n",
        "    return list(groups.values())\n",
        "\n",
        "# Test\n",
        "print(\"Group Anagrams:\")\n",
        "print(\"=\" * 60)\n",
        "strs = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]\n",
        "result = group_anagrams(strs)\n",
        "print(f\"Input: {strs}\")\n",
        "print(f\"Output: {result}\")\n",
        "print(\"Explanation: 'eat', 'tea', 'ate' are anagrams; 'tan', 'nat' are anagrams\")\n",
        "\n",
        "# Application: Group similar trip patterns\n",
        "trip_patterns = [\"NYC-SF\", \"SF-NYC\", \"LA-CHI\", \"CHI-LA\", \"NYC-LA\"]\n",
        "# Normalize by sorting origin-destination\n",
        "normalized = {}\n",
        "for pattern in trip_patterns:\n",
        "    cities = pattern.split('-')\n",
        "    key = '-'.join(sorted(cities))\n",
        "    if key not in normalized:\n",
        "        normalized[key] = []\n",
        "    normalized[key].append(pattern)\n",
        "print(f\"\\nTrip patterns: {trip_patterns}\")\n",
        "print(f\"Grouped by route: {list(normalized.values())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 19: Implement LRU Cache (System Design Component)\n",
        "\n",
        "**Difficulty:** Hard  \n",
        "**Topic:** Hash Maps, Doubly Linked Lists  \n",
        "**Use Case:** Caching, feature stores, memoization\n",
        "\n",
        "Design and implement a Least Recently Used (LRU) cache.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class LRUCache:\n",
        "    \"\"\"\n",
        "    LRU Cache implementation.\n",
        "    \n",
        "    Time Complexity: O(1) for both get and put\n",
        "    Space Complexity: O(capacity)\n",
        "    \n",
        "    Key Concept: Use OrderedDict which maintains insertion order\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.cache = OrderedDict()\n",
        "    \n",
        "    def get(self, key):\n",
        "        if key not in self.cache:\n",
        "            return -1\n",
        "        \n",
        "        # Move to end (most recently used)\n",
        "        self.cache.move_to_end(key)\n",
        "        return self.cache[key]\n",
        "    \n",
        "    def put(self, key, value):\n",
        "        if key in self.cache:\n",
        "            # Update value and move to end\n",
        "            self.cache[key] = value\n",
        "            self.cache.move_to_end(key)\n",
        "        else:\n",
        "            if len(self.cache) >= self.capacity:\n",
        "                # Remove least recently used (first item)\n",
        "                self.cache.popitem(last=False)\n",
        "            self.cache[key] = value\n",
        "\n",
        "# Test\n",
        "print(\"LRU Cache:\")\n",
        "print(\"=\" * 60)\n",
        "lru = LRUCache(2)\n",
        "lru.put(1, \"value1\")\n",
        "lru.put(2, \"value2\")\n",
        "print(f\"Get(1): {lru.get(1)}\")  # Returns \"value1\"\n",
        "lru.put(3, \"value3\")  # Evicts key 2\n",
        "print(f\"Get(2): {lru.get(2)}\")  # Returns -1 (not found)\n",
        "print(f\"Get(3): {lru.get(3)}\")  # Returns \"value3\"\n",
        "print(f\"Get(1): {lru.get(1)}\")  # Returns \"value1\"\n",
        "\n",
        "# Application: Cache frequently accessed features\n",
        "feature_cache = LRUCache(capacity=100)\n",
        "print(\"\\nFeature cache example:\")\n",
        "feature_cache.put(\"user_123_features\", {\"rating\": 4.5, \"trips\": 50})\n",
        "feature_cache.put(\"user_456_features\", {\"rating\": 4.8, \"trips\": 100})\n",
        "print(f\"Cached features for user_123: {feature_cache.get('user_123_features')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 20: Find Peak Element (Binary Search Variant)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Binary Search  \n",
        "**Use Case:** Finding local maxima, optimization problems\n",
        "\n",
        "Find a peak element (greater than neighbors) in an array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_peak_element(nums):\n",
        "    \"\"\"\n",
        "    Find peak element using binary search.\n",
        "    \n",
        "    Time Complexity: O(log n)\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: If nums[mid] < nums[mid+1], peak is in right half\n",
        "    \"\"\"\n",
        "    left, right = 0, len(nums) - 1\n",
        "    \n",
        "    while left < right:\n",
        "        mid = left + (right - left) // 2\n",
        "        \n",
        "        if nums[mid] > nums[mid + 1]:\n",
        "            # Peak is in left half (including mid)\n",
        "            right = mid\n",
        "        else:\n",
        "            # Peak is in right half\n",
        "            left = mid + 1\n",
        "    \n",
        "    return left\n",
        "\n",
        "# Test\n",
        "print(\"Find Peak Element:\")\n",
        "print(\"=\" * 60)\n",
        "nums = [1, 2, 3, 1]\n",
        "peak_idx = find_peak_element(nums)\n",
        "print(f\"Array: {nums}\")\n",
        "print(f\"Peak element at index: {peak_idx}, value: {nums[peak_idx]}\")\n",
        "\n",
        "# Application: Find peak demand hour\n",
        "hourly_demand = [10, 15, 20, 25, 30, 28, 22, 18]\n",
        "peak_hour = find_peak_element(hourly_demand)\n",
        "print(f\"\\nHourly demand: {hourly_demand}\")\n",
        "print(f\"Peak demand hour: {peak_hour} (value: {hourly_demand[peak_hour]})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 21: Word Break (Dynamic Programming)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Dynamic Programming  \n",
        "**Use Case:** Text processing, validation, parsing\n",
        "\n",
        "Determine if a string can be segmented into dictionary words.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def word_break(s, word_dict):\n",
        "    \"\"\"\n",
        "    Check if string can be segmented into dictionary words.\n",
        "    \n",
        "    Time Complexity: O(n^2) where n is string length\n",
        "    Space Complexity: O(n) for memoization\n",
        "    \n",
        "    Key Concept: DP - dp[i] = True if s[0:i] can be segmented\n",
        "    \"\"\"\n",
        "    word_set = set(word_dict)\n",
        "    n = len(s)\n",
        "    dp = [False] * (n + 1)\n",
        "    dp[0] = True  # Empty string is valid\n",
        "    \n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(i):\n",
        "            # Check if s[0:j] is valid and s[j:i] is in dictionary\n",
        "            if dp[j] and s[j:i] in word_set:\n",
        "                dp[i] = True\n",
        "                break\n",
        "    \n",
        "    return dp[n]\n",
        "\n",
        "# Test\n",
        "print(\"Word Break:\")\n",
        "print(\"=\" * 60)\n",
        "s = \"leetcode\"\n",
        "word_dict = [\"leet\", \"code\"]\n",
        "result = word_break(s, word_dict)\n",
        "print(f\"String: '{s}', Dictionary: {word_dict}\")\n",
        "print(f\"Can be segmented: {result}\")\n",
        "\n",
        "# Application: Validate trip route code\n",
        "route_codes = [\"NYC\", \"SF\", \"LA\", \"CHI\"]\n",
        "route_string = \"NYCSFLA\"\n",
        "is_valid_route = word_break(route_string, route_codes)\n",
        "print(f\"\\nRoute string: '{route_string}', Valid codes: {route_codes}\")\n",
        "print(f\"Is valid route: {is_valid_route}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 22: Implement Trie (Prefix Tree) - For Autocomplete\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Trie, Trees  \n",
        "**Use Case:** Autocomplete, prefix matching, search suggestions\n",
        "\n",
        "Implement a Trie data structure for efficient prefix searches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_end = False\n",
        "\n",
        "class Trie:\n",
        "    \"\"\"\n",
        "    Trie (Prefix Tree) implementation.\n",
        "    \n",
        "    Time Complexity:\n",
        "    - Insert: O(m) where m is word length\n",
        "    - Search: O(m)\n",
        "    - StartsWith: O(m)\n",
        "    \n",
        "    Space Complexity: O(ALPHABET_SIZE * N * M) where N is number of words, M is avg length\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "    \n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = TrieNode()\n",
        "            node = node.children[char]\n",
        "        node.is_end = True\n",
        "    \n",
        "    def search(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                return False\n",
        "            node = node.children[char]\n",
        "        return node.is_end\n",
        "    \n",
        "    def starts_with(self, prefix):\n",
        "        node = self.root\n",
        "        for char in prefix:\n",
        "            if char not in node.children:\n",
        "                return False\n",
        "            node = node.children[char]\n",
        "        return True\n",
        "    \n",
        "    def get_all_with_prefix(self, prefix):\n",
        "        \"\"\"Get all words starting with prefix\"\"\"\n",
        "        node = self.root\n",
        "        for char in prefix:\n",
        "            if char not in node.children:\n",
        "                return []\n",
        "            node = node.children[char]\n",
        "        \n",
        "        # DFS to collect all words from this node\n",
        "        results = []\n",
        "        self._dfs(node, prefix, results)\n",
        "        return results\n",
        "    \n",
        "    def _dfs(self, node, prefix, results):\n",
        "        if node.is_end:\n",
        "            results.append(prefix)\n",
        "        for char, child in node.children.items():\n",
        "            self._dfs(child, prefix + char, results)\n",
        "\n",
        "# Test\n",
        "print(\"Trie (Prefix Tree):\")\n",
        "print(\"=\" * 60)\n",
        "trie = Trie()\n",
        "words = [\"apple\", \"app\", \"application\", \"apply\", \"banana\", \"band\"]\n",
        "for word in words:\n",
        "    trie.insert(word)\n",
        "\n",
        "print(f\"Inserted words: {words}\")\n",
        "print(f\"Search 'app': {trie.search('app')}\")\n",
        "print(f\"Search 'appl': {trie.search('appl')}\")\n",
        "print(f\"Starts with 'app': {trie.starts_with('app')}\")\n",
        "print(f\"All words with prefix 'app': {trie.get_all_with_prefix('app')}\")\n",
        "\n",
        "# Application: City name autocomplete\n",
        "city_trie = Trie()\n",
        "cities = [\"New York\", \"Newark\", \"San Francisco\", \"San Diego\", \"Los Angeles\"]\n",
        "for city in cities:\n",
        "    city_trie.insert(city.lower().replace(\" \", \"\"))\n",
        "\n",
        "print(f\"\\nCity autocomplete for 'new': {city_trie.get_all_with_prefix('new')}\")\n",
        "print(f\"City autocomplete for 'san': {city_trie.get_all_with_prefix('san')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 23: Calculate Distance Between Two Points (Geospatial)\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Math, Geospatial  \n",
        "**Use Case:** Ride matching, distance calculations\n",
        "\n",
        "Calculate distance between two geographic points using Haversine formula.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calculate great circle distance between two points on Earth.\n",
        "    \n",
        "    Uses Haversine formula for spherical distance calculation.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    lat1, lon1: float\n",
        "        Latitude and longitude of first point (in degrees)\n",
        "    lat2, lon2: float\n",
        "        Latitude and longitude of second point (in degrees)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    float: Distance in kilometers\n",
        "    \"\"\"\n",
        "    # Earth radius in kilometers\n",
        "    R = 6371.0\n",
        "    \n",
        "    # Convert to radians\n",
        "    lat1_rad = math.radians(lat1)\n",
        "    lon1_rad = math.radians(lon1)\n",
        "    lat2_rad = math.radians(lat2)\n",
        "    lon2_rad = math.radians(lon2)\n",
        "    \n",
        "    # Haversine formula\n",
        "    dlat = lat2_rad - lat1_rad\n",
        "    dlon = lon2_rad - lon1_rad\n",
        "    \n",
        "    a = (math.sin(dlat / 2)**2 + \n",
        "         math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2)\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "    \n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "def euclidean_distance(x1, y1, x2, y2):\n",
        "    \"\"\"\n",
        "    Euclidean distance (for 2D plane, not Earth surface).\n",
        "    Useful for grid-based systems or small distances.\n",
        "    \"\"\"\n",
        "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "\n",
        "# Test\n",
        "print(\"Distance Calculations:\")\n",
        "print(\"=\" * 60)\n",
        "# NYC coordinates\n",
        "nyc_lat, nyc_lon = 40.7128, -74.0060\n",
        "# SF coordinates\n",
        "sf_lat, sf_lon = 37.7749, -122.4194\n",
        "\n",
        "distance_km = haversine_distance(nyc_lat, nyc_lon, sf_lat, sf_lon)\n",
        "distance_miles = distance_km * 0.621371\n",
        "\n",
        "print(f\"NYC: ({nyc_lat}, {nyc_lon})\")\n",
        "print(f\"SF: ({sf_lat}, {sf_lon})\")\n",
        "print(f\"Distance: {distance_km:.2f} km ({distance_miles:.2f} miles)\")\n",
        "\n",
        "# Application: Find closest driver to rider\n",
        "rider_location = (40.7580, -73.9855)  # Times Square, NYC\n",
        "drivers = [\n",
        "    {\"id\": 1, \"location\": (40.7614, -73.9776)},  # Central Park\n",
        "    {\"id\": 2, \"location\": (40.7505, -73.9934)},  # Penn Station\n",
        "    {\"id\": 3, \"location\": (40.7282, -73.9942)},  # SoHo\n",
        "]\n",
        "\n",
        "distances = []\n",
        "for driver in drivers:\n",
        "    dist = haversine_distance(\n",
        "        rider_location[0], rider_location[1],\n",
        "        driver[\"location\"][0], driver[\"location\"][1]\n",
        "    )\n",
        "    distances.append((driver[\"id\"], dist))\n",
        "\n",
        "closest_driver = min(distances, key=lambda x: x[1])\n",
        "print(f\"\\nRider location: {rider_location}\")\n",
        "print(f\"Closest driver: ID {closest_driver[0]}, distance: {closest_driver[1]:.2f} km\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 24: Reservoir Sampling (Streaming Data)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Probability, Algorithms  \n",
        "**Use Case:** Sampling from large/streaming datasets\n",
        "\n",
        "Implement reservoir sampling to randomly select k items from a stream of unknown size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def reservoir_sampling(stream, k):\n",
        "    \"\"\"\n",
        "    Randomly sample k items from a stream.\n",
        "    \n",
        "    Time Complexity: O(n) where n is stream size\n",
        "    Space Complexity: O(k)\n",
        "    \n",
        "    Key Concept: Each item has k/n probability of being selected\n",
        "    \"\"\"\n",
        "    reservoir = []\n",
        "    \n",
        "    for i, item in enumerate(stream):\n",
        "        if i < k:\n",
        "            # Fill reservoir with first k items\n",
        "            reservoir.append(item)\n",
        "        else:\n",
        "            # Replace with probability k/(i+1)\n",
        "            j = random.randint(0, i)\n",
        "            if j < k:\n",
        "                reservoir[j] = item\n",
        "    \n",
        "    return reservoir\n",
        "\n",
        "# Test with stream\n",
        "print(\"Reservoir Sampling:\")\n",
        "print(\"=\" * 60)\n",
        "stream = list(range(100))  # Stream of numbers 0-99\n",
        "k = 10\n",
        "sample = reservoir_sampling(stream, k)\n",
        "print(f\"Stream size: {len(stream)}, Sample size: {k}\")\n",
        "print(f\"Sample: {sorted(sample)}\")\n",
        "print(f\"Note: Each number has equal probability of being selected\")\n",
        "\n",
        "# Application: Sample trips for analysis without loading all data\n",
        "def trip_stream_generator():\n",
        "    \"\"\"Generator simulating stream of trips\"\"\"\n",
        "    for i in range(10000):\n",
        "        yield {\"trip_id\": i, \"distance\": random.uniform(1, 50)}\n",
        "\n",
        "print(\"\\nSampling trips from stream:\")\n",
        "trip_sample = reservoir_sampling(trip_stream_generator(), 100)\n",
        "print(f\"Sampled {len(trip_sample)} trips out of 10,000\")\n",
        "print(f\"Average distance in sample: {sum(t['distance'] for t in trip_sample) / len(trip_sample):.2f} km\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 25: Calculate Percentiles and Quartiles (Statistics)\n",
        "\n",
        "**Difficulty:** Easy-Medium  \n",
        "**Topic:** Statistics, Arrays  \n",
        "**Use Case:** Data analysis, outlier detection, reporting\n",
        "\n",
        "Calculate percentiles and quartiles from a dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_percentile(data, percentile):\n",
        "    \"\"\"\n",
        "    Calculate percentile value.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    data: List[float]\n",
        "        Sorted data\n",
        "    percentile: float\n",
        "        Percentile (0-100)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    float: Percentile value\n",
        "    \"\"\"\n",
        "    if not data:\n",
        "        return None\n",
        "    \n",
        "    sorted_data = sorted(data)\n",
        "    n = len(sorted_data)\n",
        "    \n",
        "    # Linear interpolation method\n",
        "    index = (percentile / 100) * (n - 1)\n",
        "    lower = int(index)\n",
        "    upper = lower + 1\n",
        "    \n",
        "    if upper >= n:\n",
        "        return sorted_data[-1]\n",
        "    \n",
        "    weight = index - lower\n",
        "    return sorted_data[lower] * (1 - weight) + sorted_data[upper] * weight\n",
        "\n",
        "def calculate_quartiles(data):\n",
        "    \"\"\"Calculate Q1, Q2 (median), Q3\"\"\"\n",
        "    return {\n",
        "        'Q1': calculate_percentile(data, 25),\n",
        "        'Q2': calculate_percentile(data, 50),\n",
        "        'Q3': calculate_percentile(data, 75)\n",
        "    }\n",
        "\n",
        "def detect_outliers_iqr(data):\n",
        "    \"\"\"\n",
        "    Detect outliers using IQR method.\n",
        "    \n",
        "    Outliers: values < Q1 - 1.5*IQR or > Q3 + 1.5*IQR\n",
        "    \"\"\"\n",
        "    quartiles = calculate_quartiles(data)\n",
        "    iqr = quartiles['Q3'] - quartiles['Q1']\n",
        "    \n",
        "    lower_bound = quartiles['Q1'] - 1.5 * iqr\n",
        "    upper_bound = quartiles['Q3'] + 1.5 * iqr\n",
        "    \n",
        "    outliers = [x for x in data if x < lower_bound or x > upper_bound]\n",
        "    \n",
        "    return outliers, lower_bound, upper_bound\n",
        "\n",
        "# Test\n",
        "print(\"Percentiles and Quartiles:\")\n",
        "print(\"=\" * 60)\n",
        "trip_durations = [15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 100, 120]  # Minutes\n",
        "\n",
        "quartiles = calculate_quartiles(trip_durations)\n",
        "print(f\"Trip durations: {trip_durations}\")\n",
        "print(f\"Q1 (25th percentile): {quartiles['Q1']:.2f}\")\n",
        "print(f\"Q2 (Median, 50th percentile): {quartiles['Q2']:.2f}\")\n",
        "print(f\"Q3 (75th percentile): {quartiles['Q3']:.2f}\")\n",
        "\n",
        "outliers, lower, upper = detect_outliers_iqr(trip_durations)\n",
        "print(f\"\\nOutliers (IQR method): {outliers}\")\n",
        "print(f\"Normal range: [{lower:.2f}, {upper:.2f}]\")\n",
        "\n",
        "# Application: Analyze wait times\n",
        "wait_times = [2, 3, 3, 4, 5, 5, 6, 7, 8, 10, 15, 20]\n",
        "p95 = calculate_percentile(wait_times, 95)\n",
        "print(f\"\\nWait times: {wait_times}\")\n",
        "print(f\"95th percentile wait time: {p95:.2f} minutes\")\n",
        "print(f\"95% of rides have wait time <= {p95:.2f} minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 26: Implement Circular Buffer (Fixed-Size Queue)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Arrays, Circular Buffer  \n",
        "**Use Case:** Sliding windows, rate limiting, recent history tracking\n",
        "\n",
        "Implement a circular buffer for efficient fixed-size queue operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CircularBuffer:\n",
        "    \"\"\"\n",
        "    Circular Buffer implementation.\n",
        "    \n",
        "    Time Complexity: O(1) for all operations\n",
        "    Space Complexity: O(capacity)\n",
        "    \n",
        "    Key Concept: Use modulo arithmetic to wrap around array indices\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.buffer = [None] * capacity\n",
        "        self.head = 0  # Write pointer\n",
        "        self.size = 0  # Current number of elements\n",
        "    \n",
        "    def enqueue(self, value):\n",
        "        \"\"\"Add element to buffer\"\"\"\n",
        "        self.buffer[self.head] = value\n",
        "        self.head = (self.head + 1) % self.capacity\n",
        "        \n",
        "        if self.size < self.capacity:\n",
        "            self.size += 1\n",
        "    \n",
        "    def get_all(self):\n",
        "        \"\"\"Get all elements in order (oldest to newest)\"\"\"\n",
        "        if self.size == 0:\n",
        "            return []\n",
        "        \n",
        "        result = []\n",
        "        start = (self.head - self.size) % self.capacity\n",
        "        \n",
        "        for i in range(self.size):\n",
        "            idx = (start + i) % self.capacity\n",
        "            result.append(self.buffer[idx])\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def get_recent(self, n):\n",
        "        \"\"\"Get n most recent elements\"\"\"\n",
        "        all_elements = self.get_all()\n",
        "        return all_elements[-n:] if n <= len(all_elements) else all_elements\n",
        "    \n",
        "    def is_full(self):\n",
        "        return self.size == self.capacity\n",
        "\n",
        "# Test\n",
        "print(\"Circular Buffer:\")\n",
        "print(\"=\" * 60)\n",
        "buffer = CircularBuffer(capacity=5)\n",
        "\n",
        "# Add elements\n",
        "for i in range(7):\n",
        "    buffer.enqueue(i)\n",
        "    print(f\"After adding {i}: {buffer.get_all()}\")\n",
        "\n",
        "print(f\"\\nBuffer is full: {buffer.is_full()}\")\n",
        "print(f\"Recent 3 elements: {buffer.get_recent(3)}\")\n",
        "\n",
        "# Application: Track recent ride requests\n",
        "request_buffer = CircularBuffer(capacity=10)\n",
        "requests = [f\"request_{i}\" for i in range(15)]\n",
        "for req in requests:\n",
        "    request_buffer.enqueue(req)\n",
        "\n",
        "print(f\"\\nRecent 5 ride requests: {request_buffer.get_recent(5)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Key Patterns and Strategies\n",
        "\n",
        "### Common Patterns:\n",
        "\n",
        "1. **Two Pointers**: Use start and end pointers moving towards each other\n",
        "   - Examples: Two Sum, Container With Most Water\n",
        "\n",
        "2. **Sliding Window**: Maintain window and slide it\n",
        "   - Examples: Longest Substring, Maximum in Window\n",
        "\n",
        "3. **Hash Map**: O(1) lookups and counting\n",
        "   - Examples: Two Sum, Group Anagrams, Top K Frequent\n",
        "\n",
        "4. **Binary Search**: Divide search space in half\n",
        "   - Examples: Search in Sorted Array, Find Peak\n",
        "\n",
        "5. **Dynamic Programming**: Solve subproblems, store results\n",
        "   - Examples: Best Time to Buy/Sell, Word Break\n",
        "\n",
        "6. **Stack/Queue**: LIFO/FIFO operations\n",
        "   - Examples: Valid Parentheses, LRU Cache\n",
        "\n",
        "7. **Trie**: Prefix tree for string operations\n",
        "   - Examples: Autocomplete, Prefix Matching\n",
        "\n",
        "### Problem-Solving Approach:\n",
        "\n",
        "1. **Understand the problem**: Read carefully, identify constraints\n",
        "2. **Brute force first**: Get working solution, then optimize\n",
        "3. **Identify pattern**: Which data structure/algorithm fits?\n",
        "4. **Optimize**: Improve time/space complexity\n",
        "5. **Edge cases**: Handle empty inputs, single elements, etc.\n",
        "6. **Test**: Verify with examples\n",
        "\n",
        "### Time Complexity Cheat Sheet:\n",
        "\n",
        "- O(1): Hash map lookup, array access\n",
        "- O(log n): Binary search, balanced tree operations\n",
        "- O(n): Single pass through array\n",
        "- O(n log n): Sorting, divide and conquer\n",
        "- O(nÂ²): Nested loops\n",
        "- O(2^n): Recursion without memoization\n",
        "\n",
        "### Practice Recommendations:\n",
        "\n",
        "1. Focus on arrays, hash maps, and sliding windows (most common)\n",
        "2. Practice binary search variants\n",
        "3. Understand when to use DP vs Greedy\n",
        "4. Know common data structures (heap, deque, Trie)\n",
        "5. Practice explaining your approach out loud\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 27: Reverse Linked List\n",
        "\n",
        "**Difficulty:** Easy-Medium  \n",
        "**Topic:** Linked Lists, Pointers  \n",
        "**Use Case:** Data structure manipulation, reversing sequences\n",
        "\n",
        "Reverse a singly linked list iteratively and recursively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ListNode:\n",
        "    def __init__(self, val=0, next=None):\n",
        "        self.val = val\n",
        "        self.next = next\n",
        "    \n",
        "    def to_list(self):\n",
        "        \"\"\"Convert linked list to Python list\"\"\"\n",
        "        result = []\n",
        "        current = self\n",
        "        while current:\n",
        "            result.append(current.val)\n",
        "            current = current.next\n",
        "        return result\n",
        "    \n",
        "    @staticmethod\n",
        "    def from_list(values):\n",
        "        \"\"\"Create linked list from Python list\"\"\"\n",
        "        if not values:\n",
        "            return None\n",
        "        head = ListNode(values[0])\n",
        "        current = head\n",
        "        for val in values[1:]:\n",
        "            current.next = ListNode(val)\n",
        "            current = current.next\n",
        "        return head\n",
        "\n",
        "def reverse_linked_list_iterative(head):\n",
        "    \"\"\"\n",
        "    Reverse linked list iteratively.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: Use three pointers to reverse links\n",
        "    \"\"\"\n",
        "    prev = None\n",
        "    current = head\n",
        "    \n",
        "    while current:\n",
        "        next_node = current.next  # Store next node\n",
        "        current.next = prev        # Reverse link\n",
        "        prev = current             # Move prev forward\n",
        "        current = next_node        # Move current forward\n",
        "    \n",
        "    return prev  # prev is new head\n",
        "\n",
        "def reverse_linked_list_recursive(head):\n",
        "    \"\"\"\n",
        "    Reverse linked list recursively.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(n) due to recursion stack\n",
        "    \n",
        "    Key Concept: Reverse rest of list, then reverse current link\n",
        "    \"\"\"\n",
        "    if not head or not head.next:\n",
        "        return head\n",
        "    \n",
        "    # Reverse rest of list\n",
        "    new_head = reverse_linked_list_recursive(head.next)\n",
        "    \n",
        "    # Reverse current link\n",
        "    head.next.next = head\n",
        "    head.next = None\n",
        "    \n",
        "    return new_head\n",
        "\n",
        "# Test\n",
        "print(\"Reverse Linked List:\")\n",
        "print(\"=\" * 60)\n",
        "original = [1, 2, 3, 4, 5]\n",
        "head1 = ListNode.from_list(original)\n",
        "head2 = ListNode.from_list(original)\n",
        "\n",
        "print(f\"Original: {original}\")\n",
        "reversed_iter = reverse_linked_list_iterative(head1)\n",
        "reversed_rec = reverse_linked_list_recursive(head2)\n",
        "\n",
        "print(f\"Iterative: {reversed_iter.to_list()}\")\n",
        "print(f\"Recursive: {reversed_rec.to_list()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 28: Validate Binary Search Tree\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Trees, Binary Search Tree  \n",
        "**Use Case:** Tree validation, data structure integrity\n",
        "\n",
        "Determine if a binary tree is a valid BST.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, val=0, left=None, right=None):\n",
        "        self.val = val\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "def is_valid_bst(root, min_val=float('-inf'), max_val=float('inf')):\n",
        "    \"\"\"\n",
        "    Validate if binary tree is a valid BST.\n",
        "    \n",
        "    Time Complexity: O(n) where n is number of nodes\n",
        "    Space Complexity: O(h) where h is height (due to recursion)\n",
        "    \n",
        "    Key Concept: Each node must be within valid range (min_val, max_val)\n",
        "    \"\"\"\n",
        "    if not root:\n",
        "        return True\n",
        "    \n",
        "    # Check if current node value is within valid range\n",
        "    if root.val <= min_val or root.val >= max_val:\n",
        "        return False\n",
        "    \n",
        "    # Recursively check left and right subtrees\n",
        "    # Left subtree: all values must be < root.val\n",
        "    # Right subtree: all values must be > root.val\n",
        "    return (is_valid_bst(root.left, min_val, root.val) and\n",
        "            is_valid_bst(root.right, root.val, max_val))\n",
        "\n",
        "def is_valid_bst_inorder(root):\n",
        "    \"\"\"\n",
        "    Alternative: Inorder traversal of valid BST gives sorted sequence.\n",
        "    \"\"\"\n",
        "    def inorder(node):\n",
        "        if not node:\n",
        "            return []\n",
        "        return inorder(node.left) + [node.val] + inorder(node.right)\n",
        "    \n",
        "    values = inorder(root)\n",
        "    return values == sorted(values) and len(values) == len(set(values))\n",
        "\n",
        "# Test\n",
        "print(\"Validate Binary Search Tree:\")\n",
        "print(\"=\" * 60)\n",
        "# Valid BST\n",
        "#       5\n",
        "#      / \\\n",
        "#     3   7\n",
        "#    / \\\n",
        "#   2   4\n",
        "root1 = TreeNode(5)\n",
        "root1.left = TreeNode(3)\n",
        "root1.right = TreeNode(7)\n",
        "root1.left.left = TreeNode(2)\n",
        "root1.left.right = TreeNode(4)\n",
        "\n",
        "# Invalid BST (4 > 3 but in left subtree of 5)\n",
        "#       5\n",
        "#      / \\\n",
        "#     3   7\n",
        "#    / \\\n",
        "#   2   6  <- 6 > 5, invalid!\n",
        "root2 = TreeNode(5)\n",
        "root2.left = TreeNode(3)\n",
        "root2.right = TreeNode(7)\n",
        "root2.left.left = TreeNode(2)\n",
        "root2.left.right = TreeNode(6)\n",
        "\n",
        "print(f\"Tree 1 (valid BST): {is_valid_bst(root1)}\")\n",
        "print(f\"Tree 2 (invalid BST): {is_valid_bst(root2)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 29: Maximum Depth of Binary Tree\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Trees, Recursion, DFS  \n",
        "**Use Case:** Tree traversal, depth calculations\n",
        "\n",
        "Find the maximum depth (height) of a binary tree.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def max_depth_recursive(root):\n",
        "    \"\"\"\n",
        "    Find maximum depth using recursion.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(h) where h is height\n",
        "    \"\"\"\n",
        "    if not root:\n",
        "        return 0\n",
        "    \n",
        "    return 1 + max(max_depth_recursive(root.left), \n",
        "                   max_depth_recursive(root.right))\n",
        "\n",
        "def max_depth_iterative(root):\n",
        "    \"\"\"\n",
        "    Find maximum depth using BFS (level-order traversal).\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(w) where w is max width\n",
        "    \"\"\"\n",
        "    if not root:\n",
        "        return 0\n",
        "    \n",
        "    from collections import deque\n",
        "    queue = deque([root])\n",
        "    depth = 0\n",
        "    \n",
        "    while queue:\n",
        "        depth += 1\n",
        "        level_size = len(queue)\n",
        "        \n",
        "        for _ in range(level_size):\n",
        "            node = queue.popleft()\n",
        "            if node.left:\n",
        "                queue.append(node.left)\n",
        "            if node.right:\n",
        "                queue.append(node.right)\n",
        "    \n",
        "    return depth\n",
        "\n",
        "# Test\n",
        "print(\"Maximum Depth of Binary Tree:\")\n",
        "print(\"=\" * 60)\n",
        "#     3\n",
        "#    / \\\n",
        "#   9   20\n",
        "#      /  \\\n",
        "#     15   7\n",
        "root = TreeNode(3)\n",
        "root.left = TreeNode(9)\n",
        "root.right = TreeNode(20)\n",
        "root.right.left = TreeNode(15)\n",
        "root.right.right = TreeNode(7)\n",
        "\n",
        "print(f\"Max depth (recursive): {max_depth_recursive(root)}\")\n",
        "print(f\"Max depth (iterative): {max_depth_iterative(root)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 30: Graph - BFS and DFS Traversal\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Graphs, BFS, DFS  \n",
        "**Use Case:** Graph exploration, path finding, connected components\n",
        "\n",
        "Implement BFS and DFS for graph traversal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import deque, defaultdict\n",
        "\n",
        "class Graph:\n",
        "    def __init__(self):\n",
        "        self.graph = defaultdict(list)\n",
        "    \n",
        "    def add_edge(self, u, v):\n",
        "        self.graph[u].append(v)\n",
        "        # For undirected graph, also add reverse\n",
        "        # self.graph[v].append(u)\n",
        "    \n",
        "    def bfs(self, start):\n",
        "        \"\"\"\n",
        "        Breadth-First Search.\n",
        "        \n",
        "        Time Complexity: O(V + E)\n",
        "        Space Complexity: O(V)\n",
        "        \n",
        "        Key Concept: Use queue, visit neighbors level by level\n",
        "        \"\"\"\n",
        "        visited = set()\n",
        "        queue = deque([start])\n",
        "        result = []\n",
        "        \n",
        "        while queue:\n",
        "            node = queue.popleft()\n",
        "            if node not in visited:\n",
        "                visited.add(node)\n",
        "                result.append(node)\n",
        "                # Add all neighbors to queue\n",
        "                for neighbor in self.graph[node]:\n",
        "                    if neighbor not in visited:\n",
        "                        queue.append(neighbor)\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def dfs_recursive(self, start, visited=None, result=None):\n",
        "        \"\"\"\n",
        "        Depth-First Search (recursive).\n",
        "        \n",
        "        Time Complexity: O(V + E)\n",
        "        Space Complexity: O(V) for recursion stack\n",
        "        \"\"\"\n",
        "        if visited is None:\n",
        "            visited = set()\n",
        "        if result is None:\n",
        "            result = []\n",
        "        \n",
        "        visited.add(start)\n",
        "        result.append(start)\n",
        "        \n",
        "        for neighbor in self.graph[start]:\n",
        "            if neighbor not in visited:\n",
        "                self.dfs_recursive(neighbor, visited, result)\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def dfs_iterative(self, start):\n",
        "        \"\"\"\n",
        "        Depth-First Search (iterative using stack).\n",
        "        \n",
        "        Time Complexity: O(V + E)\n",
        "        Space Complexity: O(V)\n",
        "        \"\"\"\n",
        "        visited = set()\n",
        "        stack = [start]\n",
        "        result = []\n",
        "        \n",
        "        while stack:\n",
        "            node = stack.pop()\n",
        "            if node not in visited:\n",
        "                visited.add(node)\n",
        "                result.append(node)\n",
        "                # Add neighbors in reverse order to maintain left-to-right\n",
        "                for neighbor in reversed(self.graph[node]):\n",
        "                    if neighbor not in visited:\n",
        "                        stack.append(neighbor)\n",
        "        \n",
        "        return result\n",
        "\n",
        "# Test\n",
        "print(\"Graph Traversal (BFS and DFS):\")\n",
        "print(\"=\" * 60)\n",
        "g = Graph()\n",
        "g.add_edge(0, 1)\n",
        "g.add_edge(0, 2)\n",
        "g.add_edge(1, 2)\n",
        "g.add_edge(2, 0)\n",
        "g.add_edge(2, 3)\n",
        "g.add_edge(3, 3)\n",
        "\n",
        "print(\"Graph structure:\")\n",
        "print(\"0 -> 1, 2\")\n",
        "print(\"1 -> 2\")\n",
        "print(\"2 -> 0, 3\")\n",
        "print(\"3 -> 3\")\n",
        "\n",
        "print(f\"\\nBFS starting from 2: {g.bfs(2)}\")\n",
        "print(f\"DFS (recursive) starting from 2: {g.dfs_recursive(2)}\")\n",
        "print(f\"DFS (iterative) starting from 2: {g.dfs_iterative(2)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 31: Climbing Stairs (Fibonacci Variant)\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Dynamic Programming, Memoization  \n",
        "**Use Case:** Optimization problems, counting combinations\n",
        "\n",
        "Find number of ways to climb n stairs (can take 1 or 2 steps at a time).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def climb_stairs_recursive(n):\n",
        "    \"\"\"\n",
        "    Recursive solution (inefficient, O(2^n)).\n",
        "    \"\"\"\n",
        "    if n <= 2:\n",
        "        return n\n",
        "    return climb_stairs_recursive(n - 1) + climb_stairs_recursive(n - 2)\n",
        "\n",
        "def climb_stairs_memoization(n, memo={}):\n",
        "    \"\"\"\n",
        "    Recursive with memoization.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(n)\n",
        "    \"\"\"\n",
        "    if n in memo:\n",
        "        return memo[n]\n",
        "    if n <= 2:\n",
        "        return n\n",
        "    memo[n] = climb_stairs_memoization(n - 1, memo) + climb_stairs_memoization(n - 2, memo)\n",
        "    return memo[n]\n",
        "\n",
        "def climb_stairs_dp(n):\n",
        "    \"\"\"\n",
        "    Dynamic programming (bottom-up).\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: Only need last two values (like Fibonacci)\n",
        "    \"\"\"\n",
        "    if n <= 2:\n",
        "        return n\n",
        "    \n",
        "    prev2 = 1  # ways to reach step 1\n",
        "    prev1 = 2  # ways to reach step 2\n",
        "    \n",
        "    for i in range(3, n + 1):\n",
        "        current = prev1 + prev2\n",
        "        prev2 = prev1\n",
        "        prev1 = current\n",
        "    \n",
        "    return prev1\n",
        "\n",
        "# Test\n",
        "print(\"Climbing Stairs:\")\n",
        "print(\"=\" * 60)\n",
        "for n in [1, 2, 3, 4, 5, 10]:\n",
        "    result = climb_stairs_dp(n)\n",
        "    print(f\"n={n}: {result} ways\")\n",
        "    # Verification: For n stairs, result should be (n+1)th Fibonacci number\n",
        "\n",
        "print(\"\\nPattern: 1, 2, 3, 5, 8, 13, 21, ... (Fibonacci sequence)\")\n",
        "print(\"Reason: Ways(n) = Ways(n-1) + Ways(n-2)\")\n",
        "\n",
        "# Application: Number of combinations for multi-step processes\n",
        "steps = 5\n",
        "print(f\"\\nWays to reach {steps} steps: {climb_stairs_dp(steps)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 32: Python Fundamentals - List Comprehensions and Generators\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Python Fundamentals  \n",
        "**Use Case:** Efficient data processing, memory optimization\n",
        "\n",
        "Demonstrate list comprehensions, generator expressions, and their differences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List Comprehension: Creates list immediately (eager evaluation)\n",
        "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "squared_list = [x**2 for x in numbers if x % 2 == 0]\n",
        "print(\"List Comprehension:\")\n",
        "print(f\"Squared even numbers: {squared_list}\")\n",
        "\n",
        "# Generator Expression: Lazy evaluation (saves memory)\n",
        "squared_gen = (x**2 for x in numbers if x % 2 == 0)\n",
        "print(\"\\nGenerator Expression:\")\n",
        "print(f\"Type: {type(squared_gen)}\")\n",
        "print(f\"Values: {list(squared_gen)}\")  # Convert to list to see values\n",
        "\n",
        "# Generator Function: More complex logic\n",
        "def fibonacci_generator(n):\n",
        "    \"\"\"Generate first n Fibonacci numbers\"\"\"\n",
        "    a, b = 0, 1\n",
        "    count = 0\n",
        "    while count < n:\n",
        "        yield a\n",
        "        a, b = b, a + b\n",
        "        count += 1\n",
        "\n",
        "print(\"\\nGenerator Function (Fibonacci):\")\n",
        "fib_gen = fibonacci_generator(10)\n",
        "print(f\"First 10 Fibonacci: {list(fib_gen)}\")\n",
        "\n",
        "# Memory comparison\n",
        "print(\"\\nMemory Comparison:\")\n",
        "import sys\n",
        "\n",
        "# List comprehension - all in memory\n",
        "big_list = [x**2 for x in range(1000000)]\n",
        "print(f\"List size: {sys.getsizeof(big_list)} bytes\")\n",
        "\n",
        "# Generator - lazy evaluation\n",
        "big_gen = (x**2 for x in range(1000000))\n",
        "print(f\"Generator size: {sys.getsizeof(big_gen)} bytes\")\n",
        "\n",
        "# Application: Process large datasets efficiently\n",
        "def process_trips_generator(trip_ids):\n",
        "    \"\"\"Generator to process trips one at a time (memory efficient)\"\"\"\n",
        "    for trip_id in trip_ids:\n",
        "        # Simulate processing\n",
        "        yield {\"trip_id\": trip_id, \"processed\": True}\n",
        "\n",
        "trip_ids = range(1000000)\n",
        "# Using generator: processes one at a time\n",
        "processed = process_trips_generator(trip_ids)\n",
        "print(f\"\\nProcessed trips (first 5): {[next(processed) for _ in range(5)]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 33: Python Decorators\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Python Fundamentals, Decorators  \n",
        "**Use Case:** Function wrapping, caching, logging, timing\n",
        "\n",
        "Implement decorators for timing, caching, and logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from functools import wraps, lru_cache\n",
        "\n",
        "# Timing Decorator\n",
        "def timer(func):\n",
        "    \"\"\"Decorator to measure function execution time\"\"\"\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f\"{func.__name__} took {end - start:.4f} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "# Caching Decorator (simple version)\n",
        "def cache_decorator(func):\n",
        "    \"\"\"Simple memoization decorator\"\"\"\n",
        "    cache = {}\n",
        "    @wraps(func)\n",
        "    def wrapper(*args):\n",
        "        if args in cache:\n",
        "            return cache[args]\n",
        "        result = func(*args)\n",
        "        cache[args] = result\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "# Logging Decorator\n",
        "def log_calls(func):\n",
        "    \"\"\"Decorator to log function calls\"\"\"\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        print(f\"Calling {func.__name__} with args={args}, kwargs={kwargs}\")\n",
        "        result = func(*args, **kwargs)\n",
        "        print(f\"{func.__name__} returned {result}\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "# Using decorators\n",
        "@timer\n",
        "@cache_decorator\n",
        "def fibonacci_slow(n):\n",
        "    \"\"\"Slow Fibonacci without memoization\"\"\"\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    return fibonacci_slow(n - 1) + fibonacci_slow(n - 2)\n",
        "\n",
        "@timer\n",
        "@lru_cache(maxsize=128)  # Built-in caching decorator\n",
        "def fibonacci_fast(n):\n",
        "    \"\"\"Fast Fibonacci with lru_cache\"\"\"\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    return fibonacci_fast(n - 1) + fibonacci_fast(n - 2)\n",
        "\n",
        "@log_calls\n",
        "def calculate_revenue(price, quantity):\n",
        "    return price * quantity\n",
        "\n",
        "# Test\n",
        "print(\"Decorators:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. Timing and Caching:\")\n",
        "print(\"Slow version (with custom cache):\")\n",
        "fib_slow_result = fibonacci_slow(30)\n",
        "print(\"\\nFast version (with lru_cache):\")\n",
        "fib_fast_result = fibonacci_fast(30)\n",
        "\n",
        "print(\"\\n2. Logging:\")\n",
        "calculate_revenue(10, 5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 34: Missing Number in Array\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Arrays, Math  \n",
        "**Use Case:** Data validation, finding gaps\n",
        "\n",
        "Find the missing number in an array containing n distinct numbers from 0 to n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def missing_number_sum(nums):\n",
        "    \"\"\"\n",
        "    Using sum formula.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: Sum of 0 to n = n*(n+1)/2\n",
        "    \"\"\"\n",
        "    n = len(nums)\n",
        "    expected_sum = n * (n + 1) // 2\n",
        "    actual_sum = sum(nums)\n",
        "    return expected_sum - actual_sum\n",
        "\n",
        "def missing_number_xor(nums):\n",
        "    \"\"\"\n",
        "    Using XOR properties.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: a XOR a = 0, a XOR 0 = a\n",
        "    \"\"\"\n",
        "    n = len(nums)\n",
        "    missing = n\n",
        "    for i, num in enumerate(nums):\n",
        "        missing ^= i ^ num\n",
        "    return missing\n",
        "\n",
        "def missing_number_set(nums):\n",
        "    \"\"\"\n",
        "    Using set for lookup.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(n)\n",
        "    \"\"\"\n",
        "    num_set = set(nums)\n",
        "    n = len(nums)\n",
        "    for i in range(n + 1):\n",
        "        if i not in num_set:\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "# Test\n",
        "print(\"Missing Number:\")\n",
        "print(\"=\" * 60)\n",
        "test_cases = [\n",
        "    [3, 0, 1],  # Missing 2\n",
        "    [0, 1],     # Missing 2\n",
        "    [9, 6, 4, 2, 3, 5, 7, 0, 1]  # Missing 8\n",
        "]\n",
        "\n",
        "for nums in test_cases:\n",
        "    result1 = missing_number_sum(nums)\n",
        "    result2 = missing_number_xor(nums)\n",
        "    result3 = missing_number_set(nums)\n",
        "    print(f\"Array: {nums}\")\n",
        "    print(f\"Missing (sum): {result1}, (XOR): {result2}, (set): {result3}\")\n",
        "    print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 35: Rotate Array\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Arrays, Two Pointers  \n",
        "**Use Case:** Array manipulation, circular shifts\n",
        "\n",
        "Rotate an array to the right by k steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rotate_array_slicing(nums, k):\n",
        "    \"\"\"\n",
        "    Using array slicing.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(n)\n",
        "    \"\"\"\n",
        "    n = len(nums)\n",
        "    k = k % n  # Handle k > n\n",
        "    nums[:] = nums[-k:] + nums[:-k]\n",
        "    return nums\n",
        "\n",
        "def rotate_array_reverse(nums, k):\n",
        "    \"\"\"\n",
        "    Using reverse trick (in-place, O(1) space).\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: Reverse entire array, then reverse first k and last n-k\n",
        "    \"\"\"\n",
        "    n = len(nums)\n",
        "    k = k % n\n",
        "    \n",
        "    # Reverse entire array\n",
        "    nums.reverse()\n",
        "    \n",
        "    # Reverse first k elements\n",
        "    nums[:k] = reversed(nums[:k])\n",
        "    \n",
        "    # Reverse remaining elements\n",
        "    nums[k:] = reversed(nums[k:])\n",
        "    \n",
        "    return nums\n",
        "\n",
        "def rotate_array_cyclic(nums, k):\n",
        "    \"\"\"\n",
        "    Cyclic replacement (in-place, O(1) space).\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1)\n",
        "    \"\"\"\n",
        "    n = len(nums)\n",
        "    k = k % n\n",
        "    start = count = 0\n",
        "    \n",
        "    while count < n:\n",
        "        current, prev = start, nums[start]\n",
        "        while True:\n",
        "            next_idx = (current + k) % n\n",
        "            nums[next_idx], prev = prev, nums[next_idx]\n",
        "            current = next_idx\n",
        "            count += 1\n",
        "            if start == current:\n",
        "                break\n",
        "        start += 1\n",
        "    \n",
        "    return nums\n",
        "\n",
        "# Test\n",
        "print(\"Rotate Array:\")\n",
        "print(\"=\" * 60)\n",
        "test_array = [1, 2, 3, 4, 5, 6, 7]\n",
        "k = 3\n",
        "print(f\"Original: {test_array}, k={k}\")\n",
        "\n",
        "# Method 1: Slicing\n",
        "arr1 = test_array.copy()\n",
        "result1 = rotate_array_slicing(arr1, k)\n",
        "print(f\"Slicing method: {result1}\")\n",
        "\n",
        "# Method 2: Reverse\n",
        "arr2 = test_array.copy()\n",
        "result2 = rotate_array_reverse(arr2, k)\n",
        "print(f\"Reverse method: {result2}\")\n",
        "\n",
        "# Method 3: Cyclic\n",
        "arr3 = test_array.copy()\n",
        "result3 = rotate_array_cyclic(arr3, k)\n",
        "print(f\"Cyclic method: {result3}\")\n",
        "\n",
        "print(f\"\\nExpected: [5, 6, 7, 1, 2, 3, 4]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 36: Container With Most Water\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Two Pointers, Greedy  \n",
        "**Use Case:** Optimization problems, area calculations\n",
        "\n",
        "Find two lines that together with x-axis forms a container that holds the most water.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def max_area(height):\n",
        "    \"\"\"\n",
        "    Two-pointer approach.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: Start with widest container, move pointer with smaller height\n",
        "    \"\"\"\n",
        "    left, right = 0, len(height) - 1\n",
        "    max_water = 0\n",
        "    \n",
        "    while left < right:\n",
        "        # Calculate area\n",
        "        width = right - left\n",
        "        current_area = width * min(height[left], height[right])\n",
        "        max_water = max(max_water, current_area)\n",
        "        \n",
        "        # Move pointer with smaller height\n",
        "        if height[left] < height[right]:\n",
        "            left += 1\n",
        "        else:\n",
        "            right -= 1\n",
        "    \n",
        "    return max_water\n",
        "\n",
        "# Test\n",
        "print(\"Container With Most Water:\")\n",
        "print(\"=\" * 60)\n",
        "heights = [1, 8, 6, 2, 5, 4, 8, 3, 7]\n",
        "result = max_area(heights)\n",
        "print(f\"Heights: {heights}\")\n",
        "print(f\"Maximum water: {result}\")\n",
        "print(\"Explanation: Lines at index 1 (height 8) and index 8 (height 7)\")\n",
        "print(f\"Area = (8-1) * min(8, 7) = 7 * 7 = {result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 37: String to Integer (atoi)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** String Manipulation  \n",
        "**Use Case:** Parsing, input validation\n",
        "\n",
        "Implement atoi function that converts string to integer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_atoi(s):\n",
        "    \"\"\"\n",
        "    Convert string to integer.\n",
        "    \n",
        "    Handle:\n",
        "    - Leading whitespace\n",
        "    - Optional +/- sign\n",
        "    - Read digits until non-digit or end\n",
        "    - Clamp to [-2^31, 2^31 - 1]\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1)\n",
        "    \"\"\"\n",
        "    if not s:\n",
        "        return 0\n",
        "    \n",
        "    # Remove leading whitespace\n",
        "    s = s.strip()\n",
        "    if not s:\n",
        "        return 0\n",
        "    \n",
        "    # Determine sign\n",
        "    sign = 1\n",
        "    if s[0] == '-':\n",
        "        sign = -1\n",
        "        s = s[1:]\n",
        "    elif s[0] == '+':\n",
        "        s = s[1:]\n",
        "    \n",
        "    # Read digits\n",
        "    result = 0\n",
        "    for char in s:\n",
        "        if not char.isdigit():\n",
        "            break\n",
        "        result = result * 10 + int(char)\n",
        "        \n",
        "        # Check overflow\n",
        "        if sign == 1 and result > 2**31 - 1:\n",
        "            return 2**31 - 1\n",
        "        if sign == -1 and result > 2**31:\n",
        "            return -2**31\n",
        "    \n",
        "    return sign * result\n",
        "\n",
        "# Test\n",
        "print(\"String to Integer (atoi):\")\n",
        "print(\"=\" * 60)\n",
        "test_cases = [\n",
        "    \"42\",\n",
        "    \"   -42\",\n",
        "    \"4193 with words\",\n",
        "    \"words and 987\",\n",
        "    \"-91283472332\",  # Overflow\n",
        "    \"91283472332\",   # Overflow\n",
        "]\n",
        "\n",
        "for s in test_cases:\n",
        "    result = my_atoi(s)\n",
        "    print(f\"'{s}' -> {result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 38: Count and Say Sequence\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Strings, Recursion  \n",
        "**Use Case:** Sequence generation, pattern recognition\n",
        "\n",
        "Generate the nth term of the count-and-say sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_and_say(n):\n",
        "    \"\"\"\n",
        "    Generate count-and-say sequence.\n",
        "    \n",
        "    Sequence: \"1\", \"11\", \"21\", \"1211\", \"111221\", ...\n",
        "    \n",
        "    Time Complexity: O(2^n) approximately\n",
        "    Space Complexity: O(2^n)\n",
        "    \"\"\"\n",
        "    if n == 1:\n",
        "        return \"1\"\n",
        "    \n",
        "    prev = count_and_say(n - 1)\n",
        "    result = []\n",
        "    count = 1\n",
        "    current_char = prev[0]\n",
        "    \n",
        "    for i in range(1, len(prev)):\n",
        "        if prev[i] == current_char:\n",
        "            count += 1\n",
        "        else:\n",
        "            result.append(str(count) + current_char)\n",
        "            count = 1\n",
        "            current_char = prev[i]\n",
        "    \n",
        "    result.append(str(count) + current_char)\n",
        "    return ''.join(result)\n",
        "\n",
        "# Iterative version (more efficient)\n",
        "def count_and_say_iterative(n):\n",
        "    result = \"1\"\n",
        "    for _ in range(n - 1):\n",
        "        new_result = []\n",
        "        count = 1\n",
        "        current_char = result[0]\n",
        "        \n",
        "        for i in range(1, len(result)):\n",
        "            if result[i] == current_char:\n",
        "                count += 1\n",
        "            else:\n",
        "                new_result.append(str(count) + current_char)\n",
        "                count = 1\n",
        "                current_char = result[i]\n",
        "        \n",
        "        new_result.append(str(count) + current_char)\n",
        "        result = ''.join(new_result)\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Test\n",
        "print(\"Count and Say:\")\n",
        "print(\"=\" * 60)\n",
        "for n in range(1, 8):\n",
        "    result = count_and_say_iterative(n)\n",
        "    print(f\"n={n}: {result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 39: Permutations (Backtracking)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Backtracking, Recursion  \n",
        "**Use Case:** Generating combinations, permutations, search problems\n",
        "\n",
        "Generate all permutations of an array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def permute_backtrack(nums):\n",
        "    \"\"\"\n",
        "    Generate all permutations using backtracking.\n",
        "    \n",
        "    Time Complexity: O(n! * n)\n",
        "    Space Complexity: O(n) for recursion stack\n",
        "    \n",
        "    Key Concept: Swap elements, recurse, then swap back\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    \n",
        "    def backtrack(start):\n",
        "        if start == len(nums):\n",
        "            result.append(nums[:])  # Make a copy\n",
        "            return\n",
        "        \n",
        "        for i in range(start, len(nums)):\n",
        "            # Swap\n",
        "            nums[start], nums[i] = nums[i], nums[start]\n",
        "            # Recurse\n",
        "            backtrack(start + 1)\n",
        "            # Backtrack (swap back)\n",
        "            nums[start], nums[i] = nums[i], nums[start]\n",
        "    \n",
        "    backtrack(0)\n",
        "    return result\n",
        "\n",
        "def permute_visited(nums):\n",
        "    \"\"\"\n",
        "    Alternative: Using visited array.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    visited = [False] * len(nums)\n",
        "    \n",
        "    def backtrack(current_perm):\n",
        "        if len(current_perm) == len(nums):\n",
        "            result.append(current_perm[:])\n",
        "            return\n",
        "        \n",
        "        for i in range(len(nums)):\n",
        "            if not visited[i]:\n",
        "                visited[i] = True\n",
        "                current_perm.append(nums[i])\n",
        "                backtrack(current_perm)\n",
        "                current_perm.pop()\n",
        "                visited[i] = False\n",
        "    \n",
        "    backtrack([])\n",
        "    return result\n",
        "\n",
        "# Test\n",
        "print(\"Permutations:\")\n",
        "print(\"=\" * 60)\n",
        "nums = [1, 2, 3]\n",
        "result1 = permute_backtrack(nums.copy())\n",
        "result2 = permute_visited(nums.copy())\n",
        "print(f\"Input: {nums}\")\n",
        "print(f\"All permutations ({len(result1)} total):\")\n",
        "for perm in result1:\n",
        "    print(f\"  {perm}\")\n",
        "\n",
        "# Using itertools (Python built-in)\n",
        "from itertools import permutations\n",
        "print(f\"\\nUsing itertools.permutations: {list(permutations(nums))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 40: Python Context Managers (with statement)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Python Fundamentals  \n",
        "**Use Case:** Resource management, file operations, database connections\n",
        "\n",
        "Implement context managers using class and decorator approaches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from contextlib import contextmanager\n",
        "\n",
        "# Context Manager using class\n",
        "class FileManager:\n",
        "    def __init__(self, filename, mode):\n",
        "        self.filename = filename\n",
        "        self.mode = mode\n",
        "        self.file = None\n",
        "    \n",
        "    def __enter__(self):\n",
        "        print(f\"Opening file {self.filename}\")\n",
        "        self.file = open(self.filename, self.mode)\n",
        "        return self.file\n",
        "    \n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        print(f\"Closing file {self.filename}\")\n",
        "        if self.file:\n",
        "            self.file.close()\n",
        "        return False  # Don't suppress exceptions\n",
        "\n",
        "# Context Manager using decorator\n",
        "@contextmanager\n",
        "def file_manager(filename, mode):\n",
        "    \"\"\"Context manager using @contextmanager decorator\"\"\"\n",
        "    print(f\"Opening file {filename}\")\n",
        "    file = open(filename, mode)\n",
        "    try:\n",
        "        yield file\n",
        "    finally:\n",
        "        print(f\"Closing file {filename}\")\n",
        "        file.close()\n",
        "\n",
        "# Custom context manager for timing\n",
        "class TimerContext:\n",
        "    def __enter__(self):\n",
        "        self.start = time.time()\n",
        "        return self\n",
        "    \n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self.elapsed = time.time() - self.start\n",
        "        print(f\"Elapsed time: {self.elapsed:.4f} seconds\")\n",
        "        return False\n",
        "\n",
        "# Test\n",
        "print(\"Context Managers:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Using class-based context manager\n",
        "with TimerContext():\n",
        "    # Simulate some work\n",
        "    sum([i**2 for i in range(1000000)])\n",
        "\n",
        "# Custom context manager example\n",
        "print(\"\\n1. Class-based context manager:\")\n",
        "class DatabaseConnection:\n",
        "    def __enter__(self):\n",
        "        print(\"Connecting to database...\")\n",
        "        return self\n",
        "    \n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        print(\"Closing database connection...\")\n",
        "        return False\n",
        "    \n",
        "    def query(self, sql):\n",
        "        print(f\"Executing: {sql}\")\n",
        "\n",
        "with DatabaseConnection() as db:\n",
        "    db.query(\"SELECT * FROM trips\")\n",
        "\n",
        "# Application: Resource management for model inference\n",
        "print(\"\\n2. Model inference context manager:\")\n",
        "class ModelInference:\n",
        "    def __init__(self, model_name):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "    \n",
        "    def __enter__(self):\n",
        "        print(f\"Loading model {self.model_name}...\")\n",
        "        # Simulate model loading\n",
        "        self.model = f\"loaded_{self.model_name}\"\n",
        "        return self\n",
        "    \n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        print(f\"Unloading model {self.model_name}...\")\n",
        "        self.model = None\n",
        "        return False\n",
        "    \n",
        "    def predict(self, data):\n",
        "        return f\"prediction for {data}\"\n",
        "\n",
        "with ModelInference(\"cancellation_model\") as model:\n",
        "    result = model.predict(\"trip_data\")\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 41: Longest Common Prefix\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Strings  \n",
        "**Use Case:** String matching, prefix operations\n",
        "\n",
        "Find the longest common prefix string amongst an array of strings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def longest_common_prefix(strs):\n",
        "    \"\"\"\n",
        "    Find longest common prefix.\n",
        "    \n",
        "    Time Complexity: O(S) where S is sum of all characters\n",
        "    Space Complexity: O(1)\n",
        "    \n",
        "    Key Concept: Compare character by character\n",
        "    \"\"\"\n",
        "    if not strs:\n",
        "        return \"\"\n",
        "    \n",
        "    # Use first string as reference\n",
        "    prefix = strs[0]\n",
        "    \n",
        "    for i in range(1, len(strs)):\n",
        "        # Compare with current string\n",
        "        while not strs[i].startswith(prefix):\n",
        "            prefix = prefix[:-1]\n",
        "            if not prefix:\n",
        "                return \"\"\n",
        "    \n",
        "    return prefix\n",
        "\n",
        "def longest_common_prefix_vertical(strs):\n",
        "    \"\"\"\n",
        "    Vertical scanning: compare character by character.\n",
        "    \"\"\"\n",
        "    if not strs:\n",
        "        return \"\"\n",
        "    \n",
        "    for i in range(len(strs[0])):\n",
        "        char = strs[0][i]\n",
        "        for j in range(1, len(strs)):\n",
        "            if i == len(strs[j]) or strs[j][i] != char:\n",
        "                return strs[0][:i]\n",
        "    \n",
        "    return strs[0]\n",
        "\n",
        "# Test\n",
        "print(\"Longest Common Prefix:\")\n",
        "print(\"=\" * 60)\n",
        "test_cases = [\n",
        "    [\"flower\", \"flow\", \"flight\"],\n",
        "    [\"dog\", \"racecar\", \"car\"],\n",
        "    [\"interspecies\", \"interstellar\", \"interstate\"],\n",
        "    [\"throne\", \"throne\"],\n",
        "    [\"\", \"b\"],\n",
        "]\n",
        "\n",
        "for strs in test_cases:\n",
        "    result1 = longest_common_prefix(strs.copy())\n",
        "    result2 = longest_common_prefix_vertical(strs.copy())\n",
        "    print(f\"Input: {strs}\")\n",
        "    print(f\"Prefix (method 1): '{result1}', (method 2): '{result2}'\")\n",
        "    print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 42: First Unique Character in String\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Hash Maps, Strings  \n",
        "**Use Case:** Finding first occurrence, character frequency\n",
        "\n",
        "Find the first non-repeating character in a string.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def first_uniq_char(s):\n",
        "    \"\"\"\n",
        "    Find first unique character.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1) - at most 26 characters\n",
        "    \n",
        "    Key Concept: Count frequencies, then find first with count=1\n",
        "    \"\"\"\n",
        "    from collections import Counter\n",
        "    count = Counter(s)\n",
        "    \n",
        "    for i, char in enumerate(s):\n",
        "        if count[char] == 1:\n",
        "            return i\n",
        "    \n",
        "    return -1\n",
        "\n",
        "def first_uniq_char_dict(s):\n",
        "    \"\"\"Alternative using dict\"\"\"\n",
        "    char_count = {}\n",
        "    \n",
        "    # Count frequencies\n",
        "    for char in s:\n",
        "        char_count[char] = char_count.get(char, 0) + 1\n",
        "    \n",
        "    # Find first unique\n",
        "    for i, char in enumerate(s):\n",
        "        if char_count[char] == 1:\n",
        "            return i\n",
        "    \n",
        "    return -1\n",
        "\n",
        "# Test\n",
        "print(\"First Unique Character:\")\n",
        "print(\"=\" * 60)\n",
        "test_cases = [\n",
        "    \"leetcode\",    # 'l' at index 0\n",
        "    \"loveleetcode\", # 'v' at index 2\n",
        "    \"aabb\",        # -1\n",
        "    \"abcdef\",      # 'a' at index 0\n",
        "]\n",
        "\n",
        "for s in test_cases:\n",
        "    result = first_uniq_char(s)\n",
        "    if result != -1:\n",
        "        print(f\"'{s}': First unique char is '{s[result]}' at index {result}\")\n",
        "    else:\n",
        "        print(f\"'{s}': No unique character (return {result})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 43: Reverse Words in String\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Strings, Two Pointers  \n",
        "**Use Case:** Text processing, string manipulation\n",
        "\n",
        "Reverse the order of words in a string.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reverse_words_split(s):\n",
        "    \"\"\"\n",
        "    Using split and join.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(n)\n",
        "    \"\"\"\n",
        "    words = s.split()\n",
        "    return ' '.join(reversed(words))\n",
        "\n",
        "def reverse_words_inplace(s):\n",
        "    \"\"\"\n",
        "    Reverse words in-place using two pointers.\n",
        "    \n",
        "    Time Complexity: O(n)\n",
        "    Space Complexity: O(1) if we ignore output string\n",
        "    \"\"\"\n",
        "    # Convert to list (strings are immutable)\n",
        "    chars = list(s)\n",
        "    n = len(chars)\n",
        "    \n",
        "    # Reverse entire string\n",
        "    def reverse(l, r):\n",
        "        while l < r:\n",
        "            chars[l], chars[r] = chars[r], chars[l]\n",
        "            l += 1\n",
        "            r -= 1\n",
        "    \n",
        "    # Reverse entire string first\n",
        "    reverse(0, n - 1)\n",
        "    \n",
        "    # Reverse each word\n",
        "    start = 0\n",
        "    for i in range(n + 1):\n",
        "        if i == n or chars[i] == ' ':\n",
        "            reverse(start, i - 1)\n",
        "            start = i + 1\n",
        "    \n",
        "    return ''.join(chars).strip()\n",
        "\n",
        "# Test\n",
        "print(\"Reverse Words in String:\")\n",
        "print(\"=\" * 60)\n",
        "test_cases = [\n",
        "    \"the sky is blue\",\n",
        "    \"  hello world  \",\n",
        "    \"a good   example\",\n",
        "    \"  Bob    Loves  Alice   \",\n",
        "]\n",
        "\n",
        "for s in test_cases:\n",
        "    result1 = reverse_words_split(s)\n",
        "    result2 = reverse_words_inplace(s)\n",
        "    print(f\"Input: '{s}'\")\n",
        "    print(f\"Output (split): '{result1}'\")\n",
        "    print(f\"Output (inplace): '{result2}'\")\n",
        "    print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 44: Implement Queue using Stacks\n",
        "\n",
        "**Difficulty:** Easy-Medium  \n",
        "**Topic:** Stacks, Queues  \n",
        "**Use Case:** Data structure implementation, understanding LIFO/FIFO\n",
        "\n",
        "Implement a queue using two stacks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyQueue:\n",
        "    \"\"\"\n",
        "    Queue using two stacks.\n",
        "    \n",
        "    Time Complexity:\n",
        "    - push: O(1)\n",
        "    - pop: O(n) amortized\n",
        "    - peek: O(n) amortized\n",
        "    \n",
        "    Space Complexity: O(n)\n",
        "    \n",
        "    Key Concept: Use two stacks - one for enqueue, one for dequeue\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.stack1 = []  # For push\n",
        "        self.stack2 = []  # For pop\n",
        "    \n",
        "    def push(self, x):\n",
        "        \"\"\"Enqueue\"\"\"\n",
        "        self.stack1.append(x)\n",
        "    \n",
        "    def pop(self):\n",
        "        \"\"\"Dequeue\"\"\"\n",
        "        self.peek()  # Move elements if needed\n",
        "        return self.stack2.pop()\n",
        "    \n",
        "    def peek(self):\n",
        "        \"\"\"Front element\"\"\"\n",
        "        if not self.stack2:\n",
        "            # Move all elements from stack1 to stack2\n",
        "            while self.stack1:\n",
        "                self.stack2.append(self.stack1.pop())\n",
        "        return self.stack2[-1]\n",
        "    \n",
        "    def empty(self):\n",
        "        return len(self.stack1) == 0 and len(self.stack2) == 0\n",
        "\n",
        "# Test\n",
        "print(\"Queue using Stacks:\")\n",
        "print(\"=\" * 60)\n",
        "queue = MyQueue()\n",
        "queue.push(1)\n",
        "queue.push(2)\n",
        "queue.push(3)\n",
        "\n",
        "print(f\"Peek: {queue.peek()}\")  # Should be 1\n",
        "print(f\"Pop: {queue.pop()}\")    # Should be 1\n",
        "print(f\"Peek: {queue.peek()}\")  # Should be 2\n",
        "print(f\"Empty: {queue.empty()}\")  # False\n",
        "queue.pop()\n",
        "queue.pop()\n",
        "print(f\"Empty after popping all: {queue.empty()}\")  # True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 45: Python Iterators and Iterables\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Python Fundamentals  \n",
        "**Use Case:** Custom iteration, lazy evaluation\n",
        "\n",
        "Implement custom iterators and understand iterables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Iterator Class\n",
        "class CountDown:\n",
        "    \"\"\"Iterator that counts down from start to stop\"\"\"\n",
        "    \n",
        "    def __init__(self, start, stop=0):\n",
        "        self.current = start\n",
        "        self.stop = stop\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.current < self.stop:\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            self.current -= 1\n",
        "            return self.current + 1\n",
        "\n",
        "# Custom Iterable (uses generator)\n",
        "class Squares:\n",
        "    \"\"\"Iterable that yields squares of numbers\"\"\"\n",
        "    \n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for i in range(self.n):\n",
        "            yield i ** 2\n",
        "\n",
        "# Iterator using generator function\n",
        "def fibonacci_iterator(n):\n",
        "    \"\"\"Generator function for Fibonacci\"\"\"\n",
        "    a, b = 0, 1\n",
        "    count = 0\n",
        "    while count < n:\n",
        "        yield a\n",
        "        a, b = b, a + b\n",
        "        count += 1\n",
        "\n",
        "# Test\n",
        "print(\"Iterators and Iterables:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"1. CountDown Iterator:\")\n",
        "countdown = CountDown(5, 0)\n",
        "for num in countdown:\n",
        "    print(f\"  {num}\", end=\" \")\n",
        "print()\n",
        "\n",
        "print(\"\\n2. Squares Iterable:\")\n",
        "squares = Squares(5)\n",
        "for square in squares:\n",
        "    print(f\"  {square}\", end=\" \")\n",
        "print()\n",
        "\n",
        "print(\"\\n3. Fibonacci Generator:\")\n",
        "fib = fibonacci_iterator(10)\n",
        "print(f\"  First 10 Fibonacci: {list(fib)}\")\n",
        "\n",
        "# Application: Custom iterator for trip data\n",
        "class TripIterator:\n",
        "    \"\"\"Iterator for processing trips\"\"\"\n",
        "    \n",
        "    def __init__(self, trip_ids):\n",
        "        self.trip_ids = trip_ids\n",
        "        self.index = 0\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.index >= len(self.trip_ids):\n",
        "            raise StopIteration\n",
        "        trip_id = self.trip_ids[self.index]\n",
        "        self.index += 1\n",
        "        return {\"trip_id\": trip_id, \"status\": \"processed\"}\n",
        "\n",
        "print(\"\\n4. Custom Trip Iterator:\")\n",
        "trips = TripIterator([101, 102, 103, 104])\n",
        "for trip in trips:\n",
        "    print(f\"  {trip}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 46: Python Lambda and Higher-Order Functions\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Python Fundamentals  \n",
        "**Use Case:** Functional programming, data transformation\n",
        "\n",
        "Demonstrate lambda functions, map, filter, and reduce.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "\n",
        "# Lambda functions\n",
        "square = lambda x: x ** 2\n",
        "add = lambda x, y: x + y\n",
        "\n",
        "print(\"Lambda Functions:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"square(5) = {square(5)}\")\n",
        "print(f\"add(3, 4) = {add(3, 4)}\")\n",
        "\n",
        "# Map: Apply function to each element\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "squared = list(map(lambda x: x**2, numbers))\n",
        "print(f\"\\nMap: {numbers} -> {squared}\")\n",
        "\n",
        "# Filter: Filter elements based on condition\n",
        "even_numbers = list(filter(lambda x: x % 2 == 0, numbers))\n",
        "print(f\"Filter (even): {numbers} -> {even_numbers}\")\n",
        "\n",
        "# Reduce: Reduce sequence to single value\n",
        "sum_all = reduce(lambda x, y: x + y, numbers)\n",
        "product = reduce(lambda x, y: x * y, numbers)\n",
        "print(f\"Reduce (sum): {numbers} -> {sum_all}\")\n",
        "print(f\"Reduce (product): {numbers} -> {product}\")\n",
        "\n",
        "# Combined: Map + Filter\n",
        "even_squares = list(map(lambda x: x**2, filter(lambda x: x % 2 == 0, numbers)))\n",
        "print(f\"Even squares: {even_squares}\")\n",
        "\n",
        "# Application: Data processing\n",
        "trips = [\n",
        "    {\"distance\": 5.2, \"fare\": 12.50},\n",
        "    {\"distance\": 3.1, \"fare\": 8.00},\n",
        "    {\"distance\": 8.7, \"fare\": 20.00},\n",
        "    {\"distance\": 2.5, \"fare\": 6.50},\n",
        "]\n",
        "\n",
        "# Filter long trips (>5km)\n",
        "long_trips = list(filter(lambda t: t[\"distance\"] > 5, trips))\n",
        "print(f\"\\nLong trips (>5km): {[t['distance'] for t in long_trips]}\")\n",
        "\n",
        "# Map: Calculate fare per km\n",
        "fare_per_km = list(map(lambda t: t[\"fare\"] / t[\"distance\"], trips))\n",
        "print(f\"Fare per km: {[f'{f:.2f}' for f in fare_per_km]}\")\n",
        "\n",
        "# Reduce: Total revenue\n",
        "total_revenue = reduce(lambda x, y: x + y, map(lambda t: t[\"fare\"], trips))\n",
        "print(f\"Total revenue: ${total_revenue:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 47: Find All Anagrams in String\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Sliding Window, Hash Maps  \n",
        "**Use Case:** Pattern matching, substring search\n",
        "\n",
        "Find all start indices of anagrams of pattern in string.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_anagrams(s, p):\n",
        "    \"\"\"\n",
        "    Find all anagram indices using sliding window.\n",
        "    \n",
        "    Time Complexity: O(n) where n is len(s)\n",
        "    Space Complexity: O(k) where k is len(p)\n",
        "    \n",
        "    Key Concept: Use sliding window with character frequency map\n",
        "    \"\"\"\n",
        "    from collections import Counter\n",
        "    \n",
        "    result = []\n",
        "    p_count = Counter(p)\n",
        "    window_count = Counter()\n",
        "    \n",
        "    # Window size\n",
        "    window_size = len(p)\n",
        "    \n",
        "    for i in range(len(s)):\n",
        "        # Add current character\n",
        "        window_count[s[i]] += 1\n",
        "        \n",
        "        # Remove character leaving window\n",
        "        if i >= window_size:\n",
        "            window_count[s[i - window_size]] -= 1\n",
        "            if window_count[s[i - window_size]] == 0:\n",
        "                del window_count[s[i - window_size]]\n",
        "        \n",
        "        # Check if window matches pattern\n",
        "        if i >= window_size - 1 and window_count == p_count:\n",
        "            result.append(i - window_size + 1)\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Test\n",
        "print(\"Find All Anagrams:\")\n",
        "print(\"=\" * 60)\n",
        "s = \"cbaebabacd\"\n",
        "p = \"abc\"\n",
        "result = find_anagrams(s, p)\n",
        "print(f\"String: '{s}', Pattern: '{p}'\")\n",
        "print(f\"Anagram indices: {result}\")\n",
        "print(f\"Anagrams found: {[s[i:i+len(p)] for i in result]}\")\n",
        "\n",
        "# Another example\n",
        "s2 = \"abab\"\n",
        "p2 = \"ab\"\n",
        "result2 = find_anagrams(s2, p2)\n",
        "print(f\"\\nString: '{s2}', Pattern: '{p2}'\")\n",
        "print(f\"Anagram indices: {result2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 48: Python Class Methods, Static Methods, and Properties\n",
        "\n",
        "**Difficulty:** Easy-Medium  \n",
        "**Topic:** Python OOP  \n",
        "**Use Case:** Object-oriented design, encapsulation\n",
        "\n",
        "Understand @classmethod, @staticmethod, and @property decorators.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Trip:\n",
        "    \"\"\"Demonstrate instance methods, class methods, static methods, and properties\"\"\"\n",
        "    \n",
        "    # Class variable\n",
        "    total_trips = 0\n",
        "    base_fare = 2.50\n",
        "    \n",
        "    def __init__(self, distance, multiplier=1.0):\n",
        "        self.distance = distance\n",
        "        self.multiplier = multiplier\n",
        "        Trip.total_trips += 1\n",
        "        self._fare = None  # Private attribute\n",
        "    \n",
        "    # Instance method: operates on instance\n",
        "    def calculate_fare(self):\n",
        "        return self.distance * Trip.base_fare * self.multiplier\n",
        "    \n",
        "    # Property: accessed like attribute but computed\n",
        "    @property\n",
        "    def fare(self):\n",
        "        if self._fare is None:\n",
        "            self._fare = self.calculate_fare()\n",
        "        return self._fare\n",
        "    \n",
        "    @fare.setter\n",
        "    def fare(self, value):\n",
        "        if value < 0:\n",
        "            raise ValueError(\"Fare cannot be negative\")\n",
        "        self._fare = value\n",
        "    \n",
        "    # Class method: operates on class, receives class as first arg\n",
        "    @classmethod\n",
        "    def from_miles(cls, miles):\n",
        "        \"\"\"Alternative constructor: create Trip from miles\"\"\"\n",
        "        km = miles * 1.60934\n",
        "        return cls(km)\n",
        "    \n",
        "    @classmethod\n",
        "    def set_base_fare(cls, fare):\n",
        "        \"\"\"Class method to change base fare for all trips\"\"\"\n",
        "        cls.base_fare = fare\n",
        "    \n",
        "    # Static method: doesn't need class or instance, just namespace\n",
        "    @staticmethod\n",
        "    def is_valid_distance(distance):\n",
        "        \"\"\"Check if distance is valid (utility function)\"\"\"\n",
        "        return 0 < distance < 1000\n",
        "    \n",
        "    @staticmethod\n",
        "    def convert_km_to_miles(km):\n",
        "        return km / 1.60934\n",
        "\n",
        "# Test\n",
        "print(\"Class Methods, Static Methods, and Properties:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Instance method\n",
        "trip1 = Trip(distance=10.0, multiplier=1.5)\n",
        "print(f\"Trip 1 fare: ${trip1.calculate_fare():.2f}\")\n",
        "\n",
        "# Property\n",
        "print(f\"Trip 1 fare (via property): ${trip1.fare:.2f}\")\n",
        "trip1.fare = 15.0\n",
        "print(f\"Trip 1 fare (after setting): ${trip1.fare:.2f}\")\n",
        "\n",
        "# Class method (alternative constructor)\n",
        "trip2 = Trip.from_miles(5.0)  # 5 miles = ~8 km\n",
        "print(f\"\\nTrip 2 from 5 miles: {trip2.distance:.2f} km\")\n",
        "\n",
        "# Class method (modify class variable)\n",
        "print(f\"\\nBase fare before: ${Trip.base_fare}\")\n",
        "Trip.set_base_fare(3.00)\n",
        "print(f\"Base fare after: ${Trip.base_fare}\")\n",
        "\n",
        "# Static method\n",
        "print(f\"\\nIs 50 km valid? {Trip.is_valid_distance(50)}\")\n",
        "print(f\"Is 2000 km valid? {Trip.is_valid_distance(2000)}\")\n",
        "print(f\"10 km in miles: {Trip.convert_km_to_miles(10):.2f}\")\n",
        "\n",
        "print(f\"\\nTotal trips created: {Trip.total_trips}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 49: Three Sum (Extension of Two Sum)\n",
        "\n",
        "**Difficulty:** Medium  \n",
        "**Topic:** Arrays, Two Pointers  \n",
        "**Use Case:** Finding triplets, combination problems\n",
        "\n",
        "Find all unique triplets that sum to zero.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def three_sum(nums, target=0):\n",
        "    \"\"\"\n",
        "    Find all unique triplets that sum to target.\n",
        "    \n",
        "    Time Complexity: O(nÂ²)\n",
        "    Space Complexity: O(1) excluding output\n",
        "    \n",
        "    Key Concept: Sort array, fix one element, use two pointers for rest\n",
        "    \"\"\"\n",
        "    nums.sort()\n",
        "    result = []\n",
        "    n = len(nums)\n",
        "    \n",
        "    for i in range(n - 2):\n",
        "        # Skip duplicates for first element\n",
        "        if i > 0 and nums[i] == nums[i - 1]:\n",
        "            continue\n",
        "        \n",
        "        left, right = i + 1, n - 1\n",
        "        \n",
        "        while left < right:\n",
        "            current_sum = nums[i] + nums[left] + nums[right]\n",
        "            \n",
        "            if current_sum == target:\n",
        "                result.append([nums[i], nums[left], nums[right]])\n",
        "                \n",
        "                # Skip duplicates\n",
        "                while left < right and nums[left] == nums[left + 1]:\n",
        "                    left += 1\n",
        "                while left < right and nums[right] == nums[right - 1]:\n",
        "                    right -= 1\n",
        "                \n",
        "                left += 1\n",
        "                right -= 1\n",
        "            elif current_sum < target:\n",
        "                left += 1\n",
        "            else:\n",
        "                right -= 1\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Test\n",
        "print(\"Three Sum:\")\n",
        "print(\"=\" * 60)\n",
        "nums = [-1, 0, 1, 2, -1, -4]\n",
        "result = three_sum(nums)\n",
        "print(f\"Array: {nums}\")\n",
        "print(f\"Triplets that sum to 0: {result}\")\n",
        "\n",
        "# Application: Find three trips with combined distance equal to target\n",
        "trip_distances = [5.2, 3.1, 8.7, 2.5, 6.3, 4.9]\n",
        "target_distance = 15.0\n",
        "# Convert to integers for three_sum\n",
        "int_distances = [int(d * 10) for d in trip_distances]\n",
        "int_target = int(target_distance * 10)\n",
        "result_trips = three_sum(int_distances, int_target)\n",
        "print(f\"\\nTrip distances: {trip_distances}\")\n",
        "print(f\"Triplets with combined distance ~{target_distance}:\")\n",
        "for triplet in result_trips:\n",
        "    indices = [int_distances.index(x) for x in triplet]\n",
        "    print(f\"  Trips {indices}: {[trip_distances[i] for i in indices]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 50: Python Exception Handling and Custom Exceptions\n",
        "\n",
        "**Difficulty:** Easy  \n",
        "**Topic:** Python Fundamentals  \n",
        "**Use Case:** Error handling, robust code, custom error types\n",
        "\n",
        "Implement custom exceptions and proper error handling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Exceptions\n",
        "class InvalidTripException(Exception):\n",
        "    \"\"\"Custom exception for invalid trip data\"\"\"\n",
        "    pass\n",
        "\n",
        "class InsufficientDataException(Exception):\n",
        "    \"\"\"Custom exception for insufficient data\"\"\"\n",
        "    def __init__(self, message, required_count, actual_count):\n",
        "        self.message = message\n",
        "        self.required_count = required_count\n",
        "        self.actual_count = actual_count\n",
        "        super().__init__(self.message)\n",
        "\n",
        "class ValidationError(Exception):\n",
        "    \"\"\"Base exception for validation errors\"\"\"\n",
        "    pass\n",
        "\n",
        "class DistanceError(ValidationError):\n",
        "    \"\"\"Distance validation error\"\"\"\n",
        "    pass\n",
        "\n",
        "# Function with exception handling\n",
        "def validate_trip(distance, duration):\n",
        "    \"\"\"\n",
        "    Validate trip data with custom exceptions.\n",
        "    \"\"\"\n",
        "    if distance <= 0:\n",
        "        raise DistanceError(f\"Distance must be positive, got {distance}\")\n",
        "    \n",
        "    if duration <= 0:\n",
        "        raise ValidationError(f\"Duration must be positive, got {duration}\")\n",
        "    \n",
        "    if distance > 1000:\n",
        "        raise InvalidTripException(f\"Distance too large: {distance} km\")\n",
        "    \n",
        "    return True\n",
        "\n",
        "def process_trips(trips):\n",
        "    \"\"\"Process trips with error handling\"\"\"\n",
        "    valid_trips = []\n",
        "    errors = []\n",
        "    \n",
        "    for trip in trips:\n",
        "        try:\n",
        "            validate_trip(trip['distance'], trip['duration'])\n",
        "            valid_trips.append(trip)\n",
        "        except DistanceError as e:\n",
        "            errors.append(f\"Distance error: {e}\")\n",
        "        except ValidationError as e:\n",
        "            errors.append(f\"Validation error: {e}\")\n",
        "        except InvalidTripException as e:\n",
        "            errors.append(f\"Invalid trip: {e}\")\n",
        "        except Exception as e:\n",
        "            errors.append(f\"Unexpected error: {e}\")\n",
        "    \n",
        "    return valid_trips, errors\n",
        "\n",
        "# Test\n",
        "print(\"Exception Handling:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test valid trip\n",
        "try:\n",
        "    validate_trip(5.2, 15)\n",
        "    print(\"âœ“ Valid trip processed\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Error: {e}\")\n",
        "\n",
        "# Test invalid distance\n",
        "try:\n",
        "    validate_trip(-5, 15)\n",
        "except DistanceError as e:\n",
        "    print(f\"âœ— Caught DistanceError: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Caught exception: {e}\")\n",
        "\n",
        "# Test processing multiple trips\n",
        "trips = [\n",
        "    {'distance': 5.2, 'duration': 15},\n",
        "    {'distance': -3.1, 'duration': 10},  # Invalid\n",
        "    {'distance': 1500, 'duration': 60},  # Invalid\n",
        "    {'distance': 8.7, 'duration': 20},\n",
        "]\n",
        "\n",
        "valid, errors = process_trips(trips)\n",
        "print(f\"\\nValid trips: {len(valid)}\")\n",
        "print(f\"Errors: {len(errors)}\")\n",
        "for error in errors:\n",
        "    print(f\"  - {error}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
